{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN6u1Ri44+0KTj57w9v+USo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JITHIN-ANTONY-JOSEPH/ERP_11358080/blob/main/10_Experiment9_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input : Recipe Instructions\n",
        "### Model : Word2Vec(Text) + Node2Vec(Graph) + Attention based Neural Networks(Model) with Negative Sampling -> V1(BATCH SIZE = 64)"
      ],
      "metadata": {
        "id": "5Be76kaXc0W5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mounting to connect to Google Drive"
      ],
      "metadata": {
        "id": "FdcuiVaMWP0o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCL0NsqYQ88N",
        "outputId": "90694675-ce5a-4456-c351-e7544d2e2ae2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing required libraries , loading datasets and pre-processing"
      ],
      "metadata": {
        "id": "L7GBovSbWXnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from node2vec import Node2Vec"
      ],
      "metadata": {
        "id": "KGlw5brmWhUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import random\n",
        "import jellyfish\n",
        "from gensim.models import Word2Vec\n",
        "import pickle\n",
        "import networkx as nx\n",
        "import json\n",
        "\n",
        "# Load the main dataset (modify the path as per your setup)\n",
        "with open('/content/drive/My Drive/ERP/modified_Processed_Layer1.json', 'r') as file:\n",
        "    recipe1m_data = [json.loads(line) for line in file]\n",
        "recipe1m_df = pd.DataFrame(recipe1m_data)\n",
        "\n",
        "# Load the substitution pairs (modify the path as per your setup)\n",
        "substitution_pairs_df = pd.read_csv('/content/drive/My Drive/ERP/Recipe1MSubs_full.csv')\n",
        "\n",
        "# Load flavor graph nodes (modify the path as per your setup)\n",
        "flavorgraph_df = pd.read_csv('/content/drive/My Drive/ERP/Dataset/nodes_191120.csv')\n",
        "\n",
        "# Load the precomputed graph embeddings\n",
        "with open('/content/drive/My Drive/ERP/MODEL_BEST_NUMBERS/graph_embeddings.pkl', 'rb') as f:\n",
        "    graph_embeddings = pickle.load(f)\n",
        "\n",
        "# Ingredient list for NER-like extraction\n",
        "ingredient_list = set(flavorgraph_df[flavorgraph_df['node_type'] == 'ingredient']['name'].dropna().unique())\n",
        "\n",
        "# Function to extract ingredients from instructions\n",
        "def extract_ingredients_from_instructions(instructions, ingredient_list):\n",
        "    extracted_ingredients = []\n",
        "    for instruction in instructions:\n",
        "        words = instruction.split()\n",
        "        for word in words:\n",
        "            if word in ingredient_list:\n",
        "                extracted_ingredients.append(word)\n",
        "    return extracted_ingredients\n",
        "\n",
        "# Apply the extraction function\n",
        "recipe1m_df['extracted_ingredients'] = recipe1m_df['processed_instructions'].apply(\n",
        "    lambda instructions: extract_ingredients_from_instructions(instructions, ingredient_list) if isinstance(instructions, list) else []\n",
        ")\n",
        "\n",
        "# Prepare sentences for training the Word2Vec model\n",
        "sentences = recipe1m_df['extracted_ingredients'].tolist()\n",
        "\n",
        "# Add substitution contexts to sentences\n",
        "for _, row in substitution_pairs_df.iterrows():\n",
        "    ingredient1 = row['ingredient1']\n",
        "    ingredient2 = row['ingredient2']\n",
        "    sentences.append([ingredient1, ingredient2])\n",
        "\n",
        "# Train the Word2Vec model\n",
        "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=8)\n",
        "\n",
        "# Generate valid substitutes dictionary\n",
        "valid_substitutes = {}\n",
        "for _, row in substitution_pairs_df.iterrows():\n",
        "    ing1 = row['ingredient1']\n",
        "    ing2 = row['ingredient2']\n",
        "    if ing1 not in valid_substitutes:\n",
        "        valid_substitutes[ing1] = set()\n",
        "    valid_substitutes[ing1].add(ing2)\n"
      ],
      "metadata": {
        "id": "tQo6-fJkWTWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to generate combined emedding"
      ],
      "metadata": {
        "id": "xkWuQWxGWa_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_combined_embedding(ingredient, text_embeddings, graph_embeddings):\n",
        "    # Get text embedding\n",
        "    if ingredient in text_embeddings:\n",
        "        text_embedding = text_embeddings[ingredient]\n",
        "    else:\n",
        "        text_embedding = np.zeros(100)\n",
        "\n",
        "    # Get graph embedding\n",
        "    if ingredient in graph_embeddings:\n",
        "        graph_embedding = graph_embeddings[ingredient]\n",
        "    else:\n",
        "        graph_embedding = np.zeros(100)\n",
        "\n",
        "    # Combine embeddings by concatenation\n",
        "    combined_embedding = np.concatenate((text_embedding, graph_embedding))\n",
        "\n",
        "    return combined_embedding"
      ],
      "metadata": {
        "id": "WDhGQ9gOXuRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining the attention based neural network"
      ],
      "metadata": {
        "id": "S0EgQIiAWcgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import json\n",
        "import jellyfish\n",
        "import random\n",
        "\n",
        "# Define the neural network with attention\n",
        "class AttentionLayer(nn.Module):\n",
        "    def __init__(self, input_dim, attention_dim):\n",
        "        super(AttentionLayer, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, attention_dim)\n",
        "        self.fc2 = nn.Linear(attention_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Compute attention scores\n",
        "        attention_scores = torch.tanh(self.fc1(x))\n",
        "        attention_scores = self.fc2(attention_scores).squeeze(-1)\n",
        "        attention_weights = F.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # Apply attention weights to input\n",
        "        weighted_sum = torch.sum(attention_weights.unsqueeze(-1) * x, dim=1)\n",
        "        return weighted_sum\n",
        "\n",
        "class CombinedNN(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, attention_dim=64):\n",
        "        super(CombinedNN, self).__init__()\n",
        "        self.attention_layer = AttentionLayer(input_dim, attention_dim)\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, output_dim)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply attention\n",
        "        x = self.attention_layer(x)\n",
        "        # Feed-forward layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "nn_model = CombinedNN(input_dim=200, output_dim=200)  # Combined embedding dimension is 200 (100 + 100)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(nn_model.parameters(), lr=0.001)\n",
        "\n",
        "# Prepare training data with negative sampling\n",
        "train_data = []\n",
        "train_labels = []\n",
        "negative_samples = []\n",
        "negative_labels = []\n",
        "\n",
        "for _, row in substitution_pairs_df.iterrows():\n",
        "    ing1 = row['ingredient1']\n",
        "    ing2 = row['ingredient2']\n",
        "\n",
        "    combined_embedding1 = get_combined_embedding(ing1, model.wv, graph_embeddings)\n",
        "    combined_embedding2 = get_combined_embedding(ing2, model.wv, graph_embeddings)\n",
        "\n",
        "    train_data.append(combined_embedding1)\n",
        "    train_labels.append(combined_embedding2)\n",
        "\n",
        "    # Generate negative samples by excluding valid substitutes\n",
        "    possible_negatives = [ing for ing in ingredient_list if ing != ing1 and ing not in valid_substitutes.get(ing1, set())]\n",
        "    selected_negatives = random.sample(possible_negatives, min(100, len(possible_negatives)))\n",
        "\n",
        "    for neg in selected_negatives:\n",
        "        neg_embedding = get_combined_embedding(neg, model.wv, graph_embeddings)\n",
        "        negative_labels.append(neg_embedding)\n",
        "        negative_samples.append(combined_embedding1)\n",
        "\n",
        "# Convert to tensors\n",
        "train_data = torch.tensor(np.array(train_data), dtype=torch.float32)\n",
        "train_labels = torch.tensor(np.array(train_labels), dtype=torch.float32)\n",
        "negative_samples = torch.tensor(np.array(negative_samples), dtype=torch.float32)\n",
        "negative_labels = torch.tensor(np.array(negative_labels), dtype=torch.float32)\n",
        "\n",
        "# Training loop with negative sampling\n",
        "for epoch in range(50):\n",
        "    nn_model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Positive pair loss\n",
        "    outputs = nn_model(train_data)\n",
        "    loss = criterion(outputs, train_labels)\n",
        "\n",
        "    # Negative pair loss (contrastive or margin-based loss)\n",
        "    neg_outputs = nn_model(negative_samples)\n",
        "    expanded_outputs = outputs.repeat_interleave(len(negative_samples) // len(train_data), dim=0)\n",
        "    negative_loss = torch.mean(torch.relu(1.0 - torch.sum(expanded_outputs * neg_outputs, dim=1)))\n",
        "\n",
        "    total_loss = loss + negative_loss\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Loss: {total_loss.item()}')\n",
        "\n",
        "# Validation process\n",
        "val_data = []\n",
        "val_labels = []\n",
        "\n",
        "for _, row in substitution_pairs_df.iterrows():\n",
        "    if len(val_data) >= 500:\n",
        "        break\n",
        "    ing1 = row['ingredient1']\n",
        "    ing2 = row['ingredient2']  # Ground truth label for validation\n",
        "\n",
        "    combined_embedding = get_combined_embedding(ing1, model.wv, graph_embeddings)\n",
        "    val_data.append(combined_embedding)\n",
        "    val_labels.append(ing2)\n",
        "\n",
        "val_data = torch.tensor(np.array(val_data), dtype=torch.float32)\n",
        "nn_model.eval()\n",
        "\n",
        "# Function to calculate cosine similarity and rank top substitutes\n",
        "def find_top_similar_ingredients(predicted_embedding, combined_embeddings, top_n=10):\n",
        "    similarities = {}\n",
        "    for ingredient, embedding in combined_embeddings.items():\n",
        "        similarity = cosine_similarity(predicted_embedding.reshape(1, -1), embedding.reshape(1, -1))[0][0]\n",
        "        similarities[ingredient] = similarity\n",
        "    sorted_ingredients = sorted(similarities.items(), key=lambda item: item[1], reverse=True)\n",
        "    return [ingredient for ingredient, similarity in sorted_ingredients[:top_n]]\n",
        "\n",
        "# Function to calculate metrics with Jaro-Winkler similarity\n",
        "def calculate_metrics(predictions, ground_truths, combined_embeddings, top_n=10, threshold=0.8):\n",
        "    mrr, hit_1, hit_3, hit_10 = 0.0, 0.0, 0.0, 0.0\n",
        "    total = len(ground_truths)\n",
        "\n",
        "    for pred, gt in zip(predictions, ground_truths):\n",
        "        top_similar = find_top_similar_ingredients(pred, combined_embeddings, top_n=top_n)\n",
        "        for rank, candidate in enumerate(top_similar, start=1):\n",
        "            sim = jellyfish.jaro_winkler_similarity(gt, candidate)\n",
        "            if sim >= threshold:\n",
        "                mrr += 1.0 / rank\n",
        "                if rank == 1:\n",
        "                    hit_1 += 1.0\n",
        "                if rank <= 3:\n",
        "                    hit_3 += 1.0\n",
        "                if rank <= 10:\n",
        "                    hit_10 += 1.0\n",
        "                break\n",
        "\n",
        "    mrr /= total\n",
        "    hit_1 /= total\n",
        "    hit_3 /= total\n",
        "    hit_10 /= total\n",
        "    return mrr, hit_1, hit_3, hit_10\n",
        "\n",
        "# Final evaluation\n",
        "val_predictions = nn_model(val_data).detach().numpy()\n",
        "combined_embeddings = {ingredient: get_combined_embedding(ingredient, model.wv, graph_embeddings) for ingredient in model.wv.index_to_key}\n",
        "\n",
        "mrr, hit_1, hit_3, hit_10 = calculate_metrics(val_predictions, val_labels, combined_embeddings)\n",
        "\n",
        "print(f\"MRR: {mrr:.4f}, Hit@1: {hit_1:.4f}, Hit@3: {hit_3:.4f}, Hit@10: {hit_10:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Gj2Ptfk4XUuE",
        "outputId": "84669cdb-902f-4be2-dd9f-971c257d51f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (1x19543 and 200x128)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-4975ebcf007b>\u001b[0m in \u001b[0;36m<cell line: 83>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m# Positive pair loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-4975ebcf007b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Feed-forward layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x19543 and 200x128)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combined Model run"
      ],
      "metadata": {
        "id": "iDkxfnOiWl3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import json\n",
        "import jellyfish\n",
        "import random\n",
        "\n",
        "# Define the neural network with attention\n",
        "class AttentionLayer(nn.Module):\n",
        "    def __init__(self, input_dim, attention_dim):\n",
        "        super(AttentionLayer, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, attention_dim)\n",
        "        self.fc2 = nn.Linear(attention_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Compute attention scores\n",
        "        attention_scores = torch.tanh(self.fc1(x))\n",
        "        attention_scores = self.fc2(attention_scores).squeeze(-1)\n",
        "        attention_weights = F.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # Apply attention weights to input\n",
        "        weighted_sum = torch.sum(attention_weights.unsqueeze(-1) * x, dim=1)\n",
        "        return weighted_sum\n",
        "\n",
        "class CombinedNN(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, attention_dim=64):\n",
        "        super(CombinedNN, self).__init__()\n",
        "        self.attention_layer = AttentionLayer(input_dim, attention_dim)\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, output_dim)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply attention\n",
        "        if x.dim() == 2:  # Ensure x is 3D: [batch_size, sequence_length, input_dim]\n",
        "            x = x.unsqueeze(1)\n",
        "        x = self.attention_layer(x)\n",
        "\n",
        "        # Feed-forward layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Load your data here - assume graph_embeddings and Word2Vec model is already initialized\n",
        "# train_data and train_labels, negative_samples, and negative_labels preparation as per previous code\n",
        "\n",
        "# Convert to tensors\n",
        "train_data = torch.tensor(np.array(train_data), dtype=torch.float32)\n",
        "train_labels = torch.tensor(np.array(train_labels), dtype=torch.float32)\n",
        "negative_samples = torch.tensor(np.array(negative_samples), dtype=torch.float32)\n",
        "negative_labels = torch.tensor(np.array(negative_labels), dtype=torch.float32)\n",
        "\n",
        "# Instantiate the model\n",
        "nn_model = CombinedNN(input_dim=200, output_dim=200)  # Combined embedding dimension is 200 (100 + 100)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(nn_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop with negative sampling\n",
        "batch_size = 64  # Define your batch size here\n",
        "num_epochs = 50  # Number of epochs\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    nn_model.train()\n",
        "    permutation = torch.randperm(train_data.size(0))\n",
        "\n",
        "    for i in range(0, train_data.size(0), batch_size):\n",
        "        indices = permutation[i:i + batch_size]\n",
        "        batch_data = train_data[indices]\n",
        "        batch_labels = train_labels[indices]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = nn_model(batch_data)\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "\n",
        "        # Negative pair loss (contrastive or margin-based loss)\n",
        "        neg_indices = permutation[i:i + batch_size]\n",
        "        batch_neg_samples = negative_samples[neg_indices]\n",
        "        neg_outputs = nn_model(batch_neg_samples)\n",
        "\n",
        "        expanded_outputs = outputs.repeat_interleave(len(neg_indices) // len(indices), dim=0)\n",
        "        negative_loss = torch.mean(torch.relu(1.0 - torch.sum(expanded_outputs * neg_outputs, dim=1)))\n",
        "\n",
        "        total_loss = loss + negative_loss\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss.item()}')\n",
        "\n",
        "# Validation process as per previous code\n",
        "# Function to calculate cosine similarity and rank top substitutes, etc.\n",
        "# Calculate metrics for validation\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf6p7KHyab8E",
        "outputId": "54d12de6-3c16-4ded-992d-45e6ff030513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 0.6616643667221069\n",
            "Epoch 2/50, Loss: 0.7021806836128235\n",
            "Epoch 3/50, Loss: 0.6991745233535767\n",
            "Epoch 4/50, Loss: 0.57625812292099\n",
            "Epoch 5/50, Loss: 0.6772568821907043\n",
            "Epoch 6/50, Loss: 0.6820120215415955\n",
            "Epoch 7/50, Loss: 0.6323806047439575\n",
            "Epoch 8/50, Loss: 0.7105088233947754\n",
            "Epoch 9/50, Loss: 0.6712614297866821\n",
            "Epoch 10/50, Loss: 0.7115906476974487\n",
            "Epoch 11/50, Loss: 0.6303530335426331\n",
            "Epoch 12/50, Loss: 0.6812475919723511\n",
            "Epoch 13/50, Loss: 0.6595089435577393\n",
            "Epoch 14/50, Loss: 0.6839166879653931\n",
            "Epoch 15/50, Loss: 0.6508415937423706\n",
            "Epoch 16/50, Loss: 0.7397512197494507\n",
            "Epoch 17/50, Loss: 0.6785586476325989\n",
            "Epoch 18/50, Loss: 0.7335115671157837\n",
            "Epoch 19/50, Loss: 0.6414223909378052\n",
            "Epoch 20/50, Loss: 0.6787993907928467\n",
            "Epoch 21/50, Loss: 0.6721693277359009\n",
            "Epoch 22/50, Loss: 0.5954175591468811\n",
            "Epoch 23/50, Loss: 0.5554666519165039\n",
            "Epoch 24/50, Loss: 0.5856977105140686\n",
            "Epoch 25/50, Loss: 0.6556739211082458\n",
            "Epoch 26/50, Loss: 0.7086564898490906\n",
            "Epoch 27/50, Loss: 0.6345674395561218\n",
            "Epoch 28/50, Loss: 0.7223836779594421\n",
            "Epoch 29/50, Loss: 0.6737741231918335\n",
            "Epoch 30/50, Loss: 0.6946481466293335\n",
            "Epoch 31/50, Loss: 0.723000168800354\n",
            "Epoch 32/50, Loss: 0.701237678527832\n",
            "Epoch 33/50, Loss: 0.7525367140769958\n",
            "Epoch 34/50, Loss: 0.6406478881835938\n",
            "Epoch 35/50, Loss: 0.7107914090156555\n",
            "Epoch 36/50, Loss: 0.6480197906494141\n",
            "Epoch 37/50, Loss: 0.6296733021736145\n",
            "Epoch 38/50, Loss: 0.6034106612205505\n",
            "Epoch 39/50, Loss: 0.6907829642295837\n",
            "Epoch 40/50, Loss: 0.7867482304573059\n",
            "Epoch 41/50, Loss: 0.6168713569641113\n",
            "Epoch 42/50, Loss: 0.7726768851280212\n",
            "Epoch 43/50, Loss: 0.6219921708106995\n",
            "Epoch 44/50, Loss: 0.8169757723808289\n",
            "Epoch 45/50, Loss: 0.7485679984092712\n",
            "Epoch 46/50, Loss: 0.705173909664154\n",
            "Epoch 47/50, Loss: 0.620208203792572\n",
            "Epoch 48/50, Loss: 0.7511679530143738\n",
            "Epoch 49/50, Loss: 0.5280827283859253\n",
            "Epoch 50/50, Loss: 0.6607174873352051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "RURZOJLJWxJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation process\n",
        "val_data = []\n",
        "val_labels = []\n",
        "\n",
        "for _, row in substitution_pairs_df.iterrows():\n",
        "    if len(val_data) >= 500:\n",
        "        break\n",
        "    ing1 = row['ingredient1']\n",
        "    ing2 = row['ingredient2']  # Ground truth label for validation\n",
        "\n",
        "    combined_embedding = get_combined_embedding(ing1, model.wv, graph_embeddings)\n",
        "    val_data.append(combined_embedding)\n",
        "    val_labels.append(ing2)\n",
        "\n",
        "val_data = torch.tensor(np.array(val_data), dtype=torch.float32)\n",
        "nn_model.eval()\n",
        "\n",
        "# Function to find the top N most similar ingredients based on cosine similarity\n",
        "def find_top_similar_ingredients(predicted_embedding, combined_embeddings, top_n=10):\n",
        "    similarities = {}\n",
        "    for ingredient, embedding in combined_embeddings.items():\n",
        "        similarity = cosine_similarity(predicted_embedding.reshape(1, -1), embedding.reshape(1, -1))[0][0]\n",
        "        similarities[ingredient] = similarity\n",
        "    sorted_ingredients = sorted(similarities.items(), key=lambda item: item[1], reverse=True)\n",
        "    return [ingredient for ingredient, similarity in sorted_ingredients[:top_n]]\n",
        "\n",
        "# Function to calculate metrics with Jaro-Winkler similarity threshold\n",
        "def calculate_metrics(predictions, ground_truths, combined_embeddings, top_n=10, threshold=0.8):\n",
        "    mrr, hit_1, hit_3, hit_10 = 0.0, 0.0, 0.0, 0.0\n",
        "    total = len(ground_truths)\n",
        "\n",
        "    for pred, gt in zip(predictions, ground_truths):\n",
        "        top_similar = find_top_similar_ingredients(pred, combined_embeddings, top_n=top_n)\n",
        "        for rank, candidate in enumerate(top_similar, start=1):\n",
        "            sim = jellyfish.jaro_winkler_similarity(gt, candidate)\n",
        "            if sim >= threshold:\n",
        "                mrr += 1.0 / rank\n",
        "                if rank == 1:\n",
        "                    hit_1 += 1.0\n",
        "                if rank <= 3:\n",
        "                    hit_3 += 1.0\n",
        "                if rank <= 10:\n",
        "                    hit_10 += 1.0\n",
        "                break\n",
        "\n",
        "    mrr /= total\n",
        "    hit_1 /= total\n",
        "    hit_3 /= total\n",
        "    hit_10 /= total\n",
        "    return mrr, hit_1, hit_3, hit_10\n",
        "\n",
        "# Final evaluation\n",
        "with torch.no_grad():\n",
        "    val_predictions = nn_model(val_data).detach().numpy()\n",
        "combined_embeddings = {ingredient: get_combined_embedding(ingredient, model.wv, graph_embeddings) for ingredient in model.wv.index_to_key}\n",
        "\n",
        "mrr, hit_1, hit_3, hit_10 = calculate_metrics(val_predictions, val_labels, combined_embeddings)\n",
        "\n",
        "print(f\"MRR: {mrr:.4f}, Hit@1: {hit_1:.4f}, Hit@3: {hit_3:.4f}, Hit@10: {hit_10:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IACz3UhwazSd",
        "outputId": "056d3e67-bfd5-4893-a59a-46ef886152da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MRR: 0.1574, Hit@1: 0.1040, Hit@3: 0.1820, Hit@10: 0.3060\n"
          ]
        }
      ]
    }
  ]
}