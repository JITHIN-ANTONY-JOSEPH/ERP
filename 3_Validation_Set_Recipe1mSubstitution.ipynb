{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "HMGi2tcnmgUg",
        "ZTB8Lw-inOhZ"
      ],
      "authorship_tag": "ABX9TyN/NYAmfM0uStGqz0XDXog1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JITHIN-ANTONY-JOSEPH/ERP_11358080/blob/main/3_Validation_Set_Recipe1mSubstitution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mounting to connect to Google Drive"
      ],
      "metadata": {
        "id": "HMGi2tcnmgUg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "danMTR-BS_6F",
        "outputId": "1a97a1e9-c134-4e76-a209-e2aa9a43ac6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing required libraries and bothe the datasets"
      ],
      "metadata": {
        "id": "2s3GBze5mpDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import re"
      ],
      "metadata": {
        "id": "Leuswm2zTNdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flavorgraph_df = pd.read_csv('/content/drive/My Drive/ERP/Dataset/nodes_191120.csv')  # Adjust the path as needed , this is the path to my personal Google Drive\n"
      ],
      "metadata": {
        "id": "RHbyJR2GTPQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Recipe1m dataset from the JSON file\n",
        "with open('/content/drive/My Drive/ERP/modified_Processed_Layer1.json', 'r') as file:  # Adjust the path as needed , this is the path to my personal Google Drive\n",
        "    recipe1m_data = [json.loads(line) for line in file]"
      ],
      "metadata": {
        "id": "zqOihnDqTlQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Core-logic to generate Recipe1MSubstitution Validation dataset"
      ],
      "metadata": {
        "id": "ngxF-IHfm1DU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "\n",
        "# Extract unique ingredients where node_type is \"ingredient\"\n",
        "flavorgraph_ingredients = set(flavorgraph_df[flavorgraph_df['node_type'] == 'ingredient']['name'].dropna().unique())\n",
        "\n",
        "# Substitution keywords\n",
        "substitution_keywords = [\"instead\", \"substitute\", \"in place of\", \"replace\"]\n",
        "\n",
        "# Convert to DataFrame for easier manipulation\n",
        "recipe1m_df = pd.DataFrame(recipe1m_data)\n",
        "\n",
        "# Function to extract substitution pairs from text\n",
        "def extract_substitution_pairs(text, ingredients_set, keywords):\n",
        "    pairs = []\n",
        "    sentences = re.split(r'[.!?]', text)\n",
        "    for sentence in sentences:\n",
        "        # Check if any multi-word keyword exists in the sentence\n",
        "        if any(keyword in sentence for keyword in keywords):\n",
        "            words = sentence.split()\n",
        "            for i in range(len(words)):\n",
        "                for keyword in keywords:\n",
        "                    keyword_len = len(keyword.split())\n",
        "                    if ' '.join(words[i:i+keyword_len]) == keyword:\n",
        "                        # Look 7 words to the left and right for ingredients\n",
        "                        left_bound = max(i - 7, 0)\n",
        "                        right_bound = min(i + keyword_len + 7, len(words))\n",
        "                        surrounding_words = words[left_bound:i] + words[i+keyword_len:right_bound]\n",
        "                        ingredient_positions = [(word, j) for j, word in enumerate(surrounding_words) if word in ingredients_set]\n",
        "                        if len(ingredient_positions) >= 2:\n",
        "                            for k in range(len(ingredient_positions) - 1):\n",
        "                                ing1 = ingredient_positions[k][0]\n",
        "                                ing2 = ingredient_positions[k + 1][0]\n",
        "                                if keyword != \"replace\":\n",
        "                                    pairs.append((ing2, ing1))\n",
        "                                else:\n",
        "                                    pairs.append((ing1, ing2))\n",
        "                        break\n",
        "    return pairs\n",
        "\n",
        "# Function to process a specific recipe row\n",
        "def process_recipe_row(row, ingredients_set, keywords):\n",
        "    substitution_pairs = []\n",
        "    if isinstance(row['processed_instructions'], list):\n",
        "        instructions = ' '.join(row['processed_instructions'])\n",
        "        pairs = extract_substitution_pairs(instructions, ingredients_set, keywords)\n",
        "        substitution_pairs.extend(pairs)\n",
        "    return substitution_pairs\n",
        "\n",
        "# Function to process a batch of recipes\n",
        "def process_batch(batch, ingredients_set, keywords):\n",
        "    batch_substitution_pairs = []\n",
        "    for index, row in batch.iterrows():\n",
        "        pairs = process_recipe_row(row, ingredients_set, keywords)\n",
        "        for pair in pairs:\n",
        "            batch_substitution_pairs.append((pair[0], pair[1], row['id'], row['partition']))\n",
        "    return batch_substitution_pairs\n",
        "\n",
        "# Split the DataFrame into batches for parallel processing\n",
        "num_batches = 10  # Adjust this number based on your system's capabilities\n",
        "batches = np.array_split(recipe1m_df, num_batches)\n",
        "\n",
        "# Process the batches in parallel\n",
        "substitution_pairs = []\n",
        "with ProcessPoolExecutor() as executor:\n",
        "    results = list(executor.map(process_batch, batches, [flavorgraph_ingredients]*num_batches, [substitution_keywords]*num_batches))\n",
        "    for result in results:\n",
        "        substitution_pairs.extend(result)\n",
        "\n",
        "# Convert the substitution pairs to a DataFrame\n",
        "substitution_pairs_df = pd.DataFrame(substitution_pairs, columns=['ingredient1', 'ingredient2', 'recipe_id', 'partition'])\n",
        "\n",
        "# Drop duplicate rows\n",
        "substitution_pairs_df = substitution_pairs_df.drop_duplicates()\n",
        "\n",
        "# Remove cases where ingredient1 equals ingredient2\n",
        "substitution_pairs_df = substitution_pairs_df[substitution_pairs_df['ingredient1'] != substitution_pairs_df['ingredient2']]\n",
        "\n",
        "# Save the substitution pairs to a CSV file\n",
        "substitution_pairs_df.to_csv('/content/drive/My Drive/ERP/Recipe1MSubs_full.csv', index=False) # Adjust the path as needed , this is the path to my personal Google Drive\n",
        "\n",
        "# Display the first few rows of the resulting DataFrame\n",
        "print(substitution_pairs_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VPexzN7Xsyr",
        "outputId": "a13bbb63-9b4a-47a2-a4b8-ea00eece3fad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ingredient1 ingredient2   recipe_id partition\n",
            "0        beef       liver  000b0b5d50     train\n",
            "1  vermicelli    couscous  000b6f9852     train\n",
            "2      orange       peach  0013894a19       val\n",
            "3  strawberry      orange  0013894a19       val\n",
            "4      orange  strawberry  0013894a19       val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating counts by partition"
      ],
      "metadata": {
        "id": "ZTB8Lw-inOhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the count of entries based on partition\n",
        "partition_counts = substitution_pairs_df['partition'].value_counts()\n",
        "\n",
        "# Display the counts\n",
        "print(partition_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4y2HqCnY3dz",
        "outputId": "c3ab1ca6-9d57-4765-e48f-b595824612b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "partition\n",
            "train    13636\n",
            "val       3008\n",
            "test      2899\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}