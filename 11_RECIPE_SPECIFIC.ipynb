{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMa3Tujtigx0IcR62dpPyZF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JITHIN-ANTONY-JOSEPH/ERP_11358080/blob/main/11_RECIPE_SPECIFIC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input : Recipe Instructions\n",
        "### Model : Word2Vec(Text) + Node2Vec(Graph) + Attention based Neural Networks(Model) with Negative Sampling -> V1(BATCH SIZE = 128) + RECIPE SPECIFIC\n",
        "**PROPOSED BEST FINAL MODEL**"
      ],
      "metadata": {
        "id": "AUI8BtgCddoR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mounting to connect to Google Drive"
      ],
      "metadata": {
        "id": "6lMEMDubmNIz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4is_6xuajQb",
        "outputId": "9805a44e-a20a-4d1e-b64f-f1d547116d1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing required libraries , loading datasets and pre-processing"
      ],
      "metadata": {
        "id": "Ntzn-eXYmSKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "v4rbvZ8WbbAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import random\n",
        "import pickle\n",
        "import json\n",
        "\n",
        "# Load the main dataset (modify the path as per your setup)\n",
        "with open('/content/drive/My Drive/ERP/modified_Processed_Layer1.json', 'r') as file: # Adjust the path as needed , this is the path to my personal Google Drive\n",
        "    recipe1m_data = [json.loads(line) for line in file]\n",
        "recipe1m_df = pd.DataFrame(recipe1m_data)\n",
        "\n",
        "# Load the substitution pairs (modify the path as per your setup)\n",
        "substitution_pairs_df = pd.read_csv('/content/drive/My Drive/ERP/Recipe1MSubs_full.csv')# Adjust the path as needed , this is the path to my personal Google Drive\n",
        "\n",
        "# Load flavor graph nodes (modify the path as per your setup)\n",
        "flavorgraph_df = pd.read_csv('/content/drive/My Drive/ERP/Dataset/nodes_191120.csv')# Adjust the path as needed , this is the path to my personal Google Drive\n",
        "\n",
        "# Load the precomputed graph embeddings\n",
        "with open('/content/drive/My Drive/ERP/MODEL_BEST_NUMBERS/graph_embeddings.pkl', 'rb') as f:# Adjust the path as needed , this is the path to my personal Google Drive\n",
        "    graph_embeddings = pickle.load(f)\n",
        "\n",
        "# Ingredient list for NER-like extraction\n",
        "ingredient_list = set(flavorgraph_df[flavorgraph_df['node_type'] == 'ingredient']['name'].dropna().unique())\n",
        "\n",
        "# Generate random embeddings for recipe IDs\n",
        "recipe_id_list = recipe1m_df['id'].unique()  # Get all unique recipe IDs\n",
        "recipe_id_embeddings = {recipe_id: np.random.rand(100) for recipe_id in recipe_id_list}  # Example: 100-dimensional embeddings\n",
        "\n",
        "# Function to extract ingredients from instructions\n",
        "def extract_ingredients_from_instructions(instructions, ingredient_list):\n",
        "    extracted_ingredients = []\n",
        "    for instruction in instructions:\n",
        "        words = instruction.split()\n",
        "        for word in words:\n",
        "            if word in ingredient_list:\n",
        "                extracted_ingredients.append(word)\n",
        "    return extracted_ingredients\n",
        "\n",
        "# Apply the extraction function\n",
        "recipe1m_df['extracted_ingredients'] = recipe1m_df['processed_instructions'].apply(\n",
        "    lambda instructions: extract_ingredients_from_instructions(instructions, ingredient_list) if isinstance(instructions, list) else []\n",
        ")\n",
        "\n",
        "# Prepare sentences for training the Word2Vec model\n",
        "sentences = recipe1m_df['extracted_ingredients'].tolist()\n",
        "\n",
        "# Add substitution contexts to sentences\n",
        "for _, row in substitution_pairs_df.iterrows():\n",
        "    ingredient1 = row['ingredient1']\n",
        "    ingredient2 = row['ingredient2']\n",
        "    sentences.append([ingredient1, ingredient2])\n",
        "\n",
        "# Train the Word2Vec model\n",
        "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=8)\n",
        "\n"
      ],
      "metadata": {
        "id": "JQnKlhBCajwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to generate combined emedding, defining the neural network and running the model"
      ],
      "metadata": {
        "id": "WrY6LJMcmZur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate valid substitutes dictionary\n",
        "valid_substitutes = {}\n",
        "for _, row in substitution_pairs_df.iterrows():\n",
        "    ing1 = row['ingredient1']\n",
        "    ing2 = row['ingredient2']\n",
        "    if ing1 not in valid_substitutes:\n",
        "        valid_substitutes[ing1] = set()\n",
        "    valid_substitutes[ing1].add(ing2)\n",
        "\n",
        "# Function to combine text, graph, and recipe ID embeddings\n",
        "def get_combined_embedding(ingredient, recipe_id, text_embeddings, graph_embeddings, recipe_id_embeddings):\n",
        "    # Get text embedding\n",
        "    if ingredient in text_embeddings:\n",
        "        text_embedding = text_embeddings[ingredient]\n",
        "    else:\n",
        "        text_embedding = np.zeros(100)\n",
        "\n",
        "    # Get graph embedding\n",
        "    if ingredient in graph_embeddings:\n",
        "        graph_embedding = graph_embeddings[ingredient]\n",
        "    else:\n",
        "        graph_embedding = np.zeros(100)\n",
        "\n",
        "    # Get recipe ID embedding\n",
        "    if recipe_id in recipe_id_embeddings:\n",
        "        recipe_embedding = recipe_id_embeddings[recipe_id]\n",
        "    else:\n",
        "        recipe_embedding = np.zeros(100)\n",
        "\n",
        "    # Combine embeddings by concatenation\n",
        "    combined_embedding = np.concatenate((text_embedding, graph_embedding, recipe_embedding))\n",
        "\n",
        "    return combined_embedding\n",
        "\n",
        "# Prepare training data with negative sampling\n",
        "train_data = []\n",
        "train_labels = []\n",
        "negative_samples = []\n",
        "negative_labels = []\n",
        "\n",
        "for _, row in substitution_pairs_df.iterrows():\n",
        "    ing1 = row['ingredient1']\n",
        "    ing2 = row['ingredient2']\n",
        "    recipe_id = row['recipe_id']  # Use recipe_id in this model\n",
        "\n",
        "    combined_embedding1 = get_combined_embedding(ing1, recipe_id, model.wv, graph_embeddings, recipe_id_embeddings)\n",
        "    combined_embedding2 = get_combined_embedding(ing2, recipe_id, model.wv, graph_embeddings, recipe_id_embeddings)\n",
        "\n",
        "    train_data.append(combined_embedding1)\n",
        "    train_labels.append(combined_embedding2)\n",
        "\n",
        "    # Generate negative samples by excluding valid substitutes\n",
        "    possible_negatives = [ing for ing in ingredient_list if ing != ing1 and ing not in valid_substitutes.get(ing1, set())]\n",
        "    selected_negatives = random.sample(possible_negatives, min(100, len(possible_negatives)))\n",
        "\n",
        "    for neg in selected_negatives:\n",
        "        neg_embedding = get_combined_embedding(neg, recipe_id, model.wv, graph_embeddings, recipe_id_embeddings)\n",
        "        negative_labels.append(neg_embedding)\n",
        "        negative_samples.append(combined_embedding1)\n",
        "\n",
        "# Convert to tensors\n",
        "train_data = torch.tensor(train_data, dtype=torch.float32)\n",
        "train_labels = torch.tensor(train_labels, dtype=torch.float32)\n",
        "negative_samples = torch.tensor(negative_samples, dtype=torch.float32)\n",
        "negative_labels = torch.tensor(negative_labels, dtype=torch.float32)\n",
        "\n",
        "# Define the neural network with attention\n",
        "class AttentionLayer(nn.Module):\n",
        "    def __init__(self, input_dim, attention_dim):\n",
        "        super(AttentionLayer, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, attention_dim)\n",
        "        self.fc2 = nn.Linear(attention_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Compute attention scores\n",
        "        attention_scores = torch.tanh(self.fc1(x))\n",
        "        attention_scores = self.fc2(attention_scores).squeeze(-1)\n",
        "        attention_weights = F.softmax(attention_scores, dim=-1)\n",
        "\n",
        "        # Apply attention weights to input\n",
        "        weighted_sum = torch.sum(attention_weights.unsqueeze(-1) * x, dim=1)\n",
        "        return weighted_sum\n",
        "\n",
        "class CombinedNN(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, attention_dim=64):\n",
        "        super(CombinedNN, self).__init__()\n",
        "        self.attention_layer = AttentionLayer(input_dim, attention_dim)\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, output_dim)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply attention\n",
        "        if x.dim() == 2:  # Ensure x is 3D: [batch_size, sequence_length, input_dim]\n",
        "            x = x.unsqueeze(1)\n",
        "        x = self.attention_layer(x)\n",
        "\n",
        "        # Feed-forward layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "nn_model = CombinedNN(input_dim=300, output_dim=300)  # Combined embedding dimension is 300 (100 text + 100 graph + 100 recipe)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(nn_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop with negative sampling\n",
        "batch_size = 128  # Define your batch size here\n",
        "num_epochs = 50  # Number of epochs\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    nn_model.train()\n",
        "    permutation = torch.randperm(train_data.size(0))\n",
        "\n",
        "    for i in range(0, train_data.size(0), batch_size):\n",
        "        indices = permutation[i:i + batch_size]\n",
        "        batch_data = train_data[indices]\n",
        "        batch_labels = train_labels[indices]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = nn_model(batch_data)\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "\n",
        "        # Negative pair loss (contrastive or margin-based loss)\n",
        "        neg_indices = permutation[i:i + batch_size]\n",
        "        batch_neg_samples = negative_samples[neg_indices]\n",
        "        neg_outputs = nn_model(batch_neg_samples)\n",
        "\n",
        "        expanded_outputs = outputs.repeat_interleave(len(neg_indices) // len(indices), dim=0)\n",
        "        negative_loss = torch.mean(torch.relu(1.0 - torch.sum(expanded_outputs * neg_outputs, dim=1)))\n",
        "\n",
        "        total_loss = loss + negative_loss\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss.item()}')\n",
        "\n",
        "# Function to extract ingredients for a specific recipe based on recipeID\n",
        "def extract_ingredients_for_recipe(recipe_id, recipe_df, ingredient_list):\n",
        "    recipe_row = recipe_df[recipe_df['id'] == recipe_id]\n",
        "    if recipe_row.empty:\n",
        "        return []\n",
        "    instructions = recipe_row.iloc[0]['processed_instructions']\n",
        "    return extract_ingredients_from_instructions(instructions, ingredient_list) if isinstance(instructions, list) else []\n",
        "\n",
        "# Modified function to filter valid substitutes for a given recipeID and ingredient\n",
        "def get_valid_substitutes(recipe_id, ingredient, recipe_df, model, graph_embeddings, recipe_id_embeddings, valid_substitutes, top_n=10):\n",
        "    # Extract context ingredients from the recipe\n",
        "    context_ingredients = extract_ingredients_for_recipe(recipe_id, recipe_df, ingredient_list)\n",
        "\n",
        "    if ingredient not in context_ingredients:\n",
        "        print(f\"Ingredient {ingredient} not found in recipe {recipe_id}.\")\n",
        "        return []\n",
        "\n",
        "    # Get combined embedding for the input ingredient\n",
        "    ingredient_embedding = get_combined_embedding(ingredient, recipe_id, model.wv, graph_embeddings, recipe_id_embeddings)\n",
        "\n",
        "    # Get all potential substitutes\n",
        "    potential_substitutes = valid_substitutes.get(ingredient, [])\n",
        "\n",
        "    # Filter substitutes that are in the context of the recipe\n",
        "    potential_substitutes = [sub for sub in potential_substitutes if sub in context_ingredients]\n",
        "\n",
        "    if not potential_substitutes:\n",
        "        print(f\"No valid substitutes found in context for ingredient {ingredient} in recipe {recipe_id}.\")\n",
        "        return []\n",
        "\n",
        "    # Calculate cosine similarity and find the top substitutes\n",
        "    substitutes = []\n",
        "    for sub in potential_substitutes:\n",
        "        sub_embedding = get_combined_embedding(sub, recipe_id, model.wv, graph_embeddings, recipe_id_embeddings)\n",
        "        similarity = cosine_similarity(ingredient_embedding.reshape(1, -1), sub_embedding.reshape(1, -1))[0][0]\n",
        "        substitutes.append((sub, similarity))\n",
        "\n",
        "    substitutes = sorted(substitutes, key=lambda x: x[1], reverse=True)[:top_n]\n",
        "    print(substitutes)\n",
        "    return [sub[0] for sub in substitutes]\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfvfV4tWbih_",
        "outputId": "0dff3b68-1e53-483e-d89b-f81935c2a88a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-fce9eaf98fe5>:62: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  train_data = torch.tensor(train_data, dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Loss: 0.48097413778305054\n",
            "Epoch 2/50, Loss: 0.4775213599205017\n",
            "Epoch 3/50, Loss: 0.47219714522361755\n",
            "Epoch 4/50, Loss: 0.4489995539188385\n",
            "Epoch 5/50, Loss: 0.4367998540401459\n",
            "Epoch 6/50, Loss: 0.48261579871177673\n",
            "Epoch 7/50, Loss: 0.4547628164291382\n",
            "Epoch 8/50, Loss: 0.4538419246673584\n",
            "Epoch 9/50, Loss: 0.45715194940567017\n",
            "Epoch 10/50, Loss: 0.46239030361175537\n",
            "Epoch 11/50, Loss: 0.46768951416015625\n",
            "Epoch 12/50, Loss: 0.43980035185813904\n",
            "Epoch 13/50, Loss: 0.4363708794116974\n",
            "Epoch 14/50, Loss: 0.44432759284973145\n",
            "Epoch 15/50, Loss: 0.4821905791759491\n",
            "Epoch 16/50, Loss: 0.43044084310531616\n",
            "Epoch 17/50, Loss: 0.45188960433006287\n",
            "Epoch 18/50, Loss: 0.44796231389045715\n",
            "Epoch 19/50, Loss: 0.46891504526138306\n",
            "Epoch 20/50, Loss: 0.4287979006767273\n",
            "Epoch 21/50, Loss: 0.4378634989261627\n",
            "Epoch 22/50, Loss: 0.4695764482021332\n",
            "Epoch 23/50, Loss: 0.4602090120315552\n",
            "Epoch 24/50, Loss: 0.48366451263427734\n",
            "Epoch 25/50, Loss: 0.4418071508407593\n",
            "Epoch 26/50, Loss: 0.45714786648750305\n",
            "Epoch 27/50, Loss: 0.4688923954963684\n",
            "Epoch 28/50, Loss: 0.48096752166748047\n",
            "Epoch 29/50, Loss: 0.4715088903903961\n",
            "Epoch 30/50, Loss: 0.4041413962841034\n",
            "Epoch 31/50, Loss: 0.4722907543182373\n",
            "Epoch 32/50, Loss: 0.43729570508003235\n",
            "Epoch 33/50, Loss: 0.4706963896751404\n",
            "Epoch 34/50, Loss: 0.4161522686481476\n",
            "Epoch 35/50, Loss: 0.5756863951683044\n",
            "Epoch 36/50, Loss: 0.4343421459197998\n",
            "Epoch 37/50, Loss: 0.49429643154144287\n",
            "Epoch 38/50, Loss: 0.46680423617362976\n",
            "Epoch 39/50, Loss: 0.4692315459251404\n",
            "Epoch 40/50, Loss: 0.42412278056144714\n",
            "Epoch 41/50, Loss: 0.42060351371765137\n",
            "Epoch 42/50, Loss: 0.44643810391426086\n",
            "Epoch 43/50, Loss: 0.4547419846057892\n",
            "Epoch 44/50, Loss: 0.45235124230384827\n",
            "Epoch 45/50, Loss: 0.4691111743450165\n",
            "Epoch 46/50, Loss: 0.4401698708534241\n",
            "Epoch 47/50, Loss: 0.4412187337875366\n",
            "Epoch 48/50, Loss: 0.46262627840042114\n",
            "Epoch 49/50, Loss: 0.4595770537853241\n",
            "Epoch 50/50, Loss: 0.4703749716281891\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting valid substitutes - Validation"
      ],
      "metadata": {
        "id": "NDFojzkMmin3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "recipe_id = \"0032493a22\"  # Replace with the actual recipe ID\n",
        "ingredient_to_replace = \"vanilla\"  # Replace with the ingredient you want to substitute\n",
        "\n",
        "top_substitutes = get_valid_substitutes(recipe_id, ingredient_to_replace, recipe1m_df, model, graph_embeddings, recipe_id_embeddings, valid_substitutes)\n",
        "\n",
        "print(f\"Top substitutes for {ingredient_to_replace} in recipe {recipe_id}: {top_substitutes}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFuJ5JtPbo2r",
        "outputId": "95bfc5b7-ee89-457e-d702-a14d4df6caea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('almond_extract', 0.6400206914192298), ('chocolate', 0.5323698887546771), ('sugar', 0.5191019816008007), ('flour', 0.4456575118104007), ('butter', 0.33350217272881116), ('lemon_rind', 0.33138547555210773), ('cream', 0.2942671854626668), ('lemon_juice', 0.08823140024502203)]\n",
            "Top substitutes for vanilla in recipe 0032493a22: ['almond_extract', 'chocolate', 'sugar', 'flour', 'butter', 'lemon_rind', 'cream', 'lemon_juice']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Savng the model and embeddings"
      ],
      "metadata": {
        "id": "Ut-k3Y7Bmngd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define the path where you want to save the model and other components\n",
        "model_save_path = '/content/drive/My Drive/ERP/RECIPE_SPECIFIC_ATTENTION/saved_model.pth'\n",
        "embeddings_save_path = '/content/drive/My Drive/ERP/RECIPE_SPECIFIC_ATTENTION/saved_embeddings.pkl'\n",
        "\n",
        "# Save the model's state dictionary\n",
        "torch.save({\n",
        "    'model_state_dict': nn_model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'epoch': epoch,  # Save the last epoch if you want to resume training later\n",
        "}, model_save_path)\n",
        "\n",
        "# Save the embeddings (text, graph, and recipe ID embeddings) if needed\n",
        "embeddings_data = {\n",
        "    'text_embeddings': model.wv,\n",
        "    'graph_embeddings': graph_embeddings,\n",
        "    'recipe_id_embeddings': recipe_id_embeddings\n",
        "}\n",
        "\n",
        "with open(embeddings_save_path, 'wb') as f:\n",
        "    pickle.dump(embeddings_data, f)\n",
        "\n",
        "print(f\"Model saved to {model_save_path}\")\n",
        "print(f\"Embeddings saved to {embeddings_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk3ZruI6dHcn",
        "outputId": "3e812641-1ad3-4d28-8933-47d221cef811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/drive/My Drive/ERP/RECIPE_SPECIFIC_ATTENTION/saved_model.pth\n",
            "Embeddings saved to /content/drive/My Drive/ERP/RECIPE_SPECIFIC_ATTENTION/saved_embeddings.pkl\n"
          ]
        }
      ]
    }
  ]
}