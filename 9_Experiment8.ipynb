{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOHQQuSfVGBlyHq7cQDS1gD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "49f3d50b7c50455aac5e86024599d26e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_effb15fb8fa74fa0a9b988b1684d8ece",
              "IPY_MODEL_ac6ffe3dbc0e49509ce8d7871f23eaa0",
              "IPY_MODEL_647ca0a50ca04acf998a6515db6303f2"
            ],
            "layout": "IPY_MODEL_3258a2dd0f304f64a46794cef784c0c8"
          }
        },
        "effb15fb8fa74fa0a9b988b1684d8ece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b81b22c8629b4f5d90385f0e5858787d",
            "placeholder": "​",
            "style": "IPY_MODEL_335a1aab17e14fa3966ce616cd7df730",
            "value": "Computing transition probabilities: 100%"
          }
        },
        "ac6ffe3dbc0e49509ce8d7871f23eaa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7850b43fa1ed4aa79b11e8ccadc3ec55",
            "max": 6651,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b855b3ca30b1442d88b1fb7e3ebaf269",
            "value": 6651
          }
        },
        "647ca0a50ca04acf998a6515db6303f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f02bf9d71bcb456a9ec4d415d18ac036",
            "placeholder": "​",
            "style": "IPY_MODEL_54818bf2a1f747afbc9a7326d746d21e",
            "value": " 6651/6651 [06:46&lt;00:00, 13.35it/s]"
          }
        },
        "3258a2dd0f304f64a46794cef784c0c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b81b22c8629b4f5d90385f0e5858787d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "335a1aab17e14fa3966ce616cd7df730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7850b43fa1ed4aa79b11e8ccadc3ec55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b855b3ca30b1442d88b1fb7e3ebaf269": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f02bf9d71bcb456a9ec4d415d18ac036": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54818bf2a1f747afbc9a7326d746d21e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JITHIN-ANTONY-JOSEPH/ERP_11358080/blob/main/9_Experiment8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input : Recipe Instructions\n",
        "### Model : Word2Vec(Text) + Node2Vec(Graph) + Neural Networks(Model) with Negative Sampling"
      ],
      "metadata": {
        "id": "DEhe7cLqcdfD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mounting to connect to Google Drive"
      ],
      "metadata": {
        "id": "jvv06Jm_VfKN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiIcmp-cB6um",
        "outputId": "f2f51756-18c1-43c7-ef53-a92badc32d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing required libraries"
      ],
      "metadata": {
        "id": "70xLc2hkVhgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install node2vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pnnEVuFDylk",
        "outputId": "5a11cc55-cfa5-49d7-d7c3-342d3333294e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: node2vec in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: gensim<5.0.0,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from node2vec) (4.3.3)\n",
            "Requirement already satisfied: joblib<2.0.0,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from node2vec) (1.4.2)\n",
            "Requirement already satisfied: networkx<4.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from node2vec) (3.3)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from node2vec) (1.26.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from node2vec) (4.66.5)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.0->node2vec) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.0->node2vec) (7.0.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim<5.0.0,>=4.3.0->node2vec) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Importing required libraries , loading datasets, pre-processing, combined embeddings , negative sampling , final_model and evaluation"
      ],
      "metadata": {
        "id": "49nfpsYiVj4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import json\n",
        "import jellyfish\n",
        "import random\n",
        "\n",
        "# Load the main dataset\n",
        "with open('/content/drive/My Drive/ERP/modified_Processed_Layer1.json', 'r') as file: # Adjust the path as needed , this is the path to my personal Google Drive\n",
        "    recipe1m_data = [json.loads(line) for line in file]\n",
        "\n",
        "recipe1m_df = pd.DataFrame(recipe1m_data)\n",
        "\n",
        "# Load the substitution pairs\n",
        "substitution_pairs_df = pd.read_csv('/content/drive/My Drive/ERP/Recipe1MSubs_full.csv')# Adjust the path as needed , this is the path to my personal Google Drive\n",
        "\n",
        "# Load flavor graph\n",
        "flavorgraph_df = pd.read_csv('/content/drive/My Drive/ERP/Dataset/nodes_191120.csv')  # Adjust the path as needed , this is the path to my personal Google Drive\n",
        "\n",
        "# Example ingredient list for NER-like extraction (replace with your own comprehensive list or use NER model)\n",
        "ingredient_list = set(flavorgraph_df[flavorgraph_df['node_type'] == 'ingredient']['name'].dropna().unique())\n",
        "\n",
        "# Function to extract ingredients from instructions\n",
        "def extract_ingredients_from_instructions(instructions, ingredient_list):\n",
        "    extracted_ingredients = []\n",
        "    for instruction in instructions:\n",
        "        words = instruction.split()\n",
        "        for word in words:\n",
        "            if word in ingredient_list:\n",
        "                extracted_ingredients.append(word)\n",
        "    return extracted_ingredients\n",
        "\n",
        "# Apply the extraction function\n",
        "recipe1m_df['extracted_ingredients'] = recipe1m_df['processed_instructions'].apply(\n",
        "    lambda instructions: extract_ingredients_from_instructions(instructions, ingredient_list) if isinstance(instructions, list) else []\n",
        ")\n",
        "\n",
        "# Prepare sentences for training\n",
        "sentences = recipe1m_df['extracted_ingredients'].tolist()\n",
        "\n",
        "# Add substitution contexts to sentences\n",
        "for _, row in substitution_pairs_df.iterrows():\n",
        "    ingredient1 = row['ingredient1']\n",
        "    ingredient2 = row['ingredient2']\n",
        "    sentences.append([ingredient1, ingredient2])\n",
        "\n",
        "# Train the Word2Vec model\n",
        "from gensim.models import Word2Vec\n",
        "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=8)\n",
        "\n",
        "# Generate the valid substitutes dictionary\n",
        "valid_substitutes = {}\n",
        "for _, row in substitution_pairs_df.iterrows():\n",
        "    ing1 = row['ingredient1']\n",
        "    ing2 = row['ingredient2']\n",
        "    if ing1 not in valid_substitutes:\n",
        "        valid_substitutes[ing1] = set()\n",
        "    valid_substitutes[ing1].add(ing2)\n",
        "\n",
        "# Import networkx and Node2Vec for the graph\n",
        "import networkx as nx\n",
        "from node2vec import Node2Vec\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# Load the knowledge graph\n",
        "flavor_graph = nx.read_graphml('/content/drive/My Drive/ERP/knowledge_graph.graphml')\n",
        "\n",
        "# Function to filter ingredient nodes in parallel\n",
        "def filter_ingredient_nodes(node, attr):\n",
        "    return node if attr['node_type'] == 'ingredient' else None\n",
        "\n",
        "# Parallelize the filtering process\n",
        "ingredient_nodes = Parallel(n_jobs=-1)(delayed(filter_ingredient_nodes)(n, attr) for n, attr in flavor_graph.nodes(data=True))\n",
        "ingredient_nodes = [node for node in ingredient_nodes if node is not None]\n",
        "\n",
        "# Create a subgraph with only ingredient nodes\n",
        "flavor_graph = flavor_graph.subgraph(ingredient_nodes)\n",
        "\n",
        "# Generate Node2Vec embeddings considering edge weights\n",
        "node2vec = Node2Vec(flavor_graph, dimensions=100, walk_length=30, num_walks=200, workers=16, weight_key='weight')\n",
        "graph_model = node2vec.fit(window=10, min_count=1, batch_words=128)\n",
        "\n",
        "# Generate graph embeddings for the ingredients\n",
        "graph_embeddings = {str(node): graph_model.wv[str(node)] for node in flavor_graph.nodes()}\n",
        "\n",
        "# Function to combine text and graph embeddings\n",
        "def get_combined_embedding(ingredient, text_embeddings, graph_embeddings):\n",
        "    # Get text embedding\n",
        "    if ingredient in text_embeddings:\n",
        "        text_embedding = text_embeddings[ingredient]\n",
        "    else:\n",
        "        text_embedding = np.zeros(100)\n",
        "\n",
        "    # Get graph embedding\n",
        "    if ingredient in graph_embeddings:\n",
        "        graph_embedding = graph_embeddings[ingredient]\n",
        "    else:\n",
        "        graph_embedding = np.zeros(100)\n",
        "\n",
        "    # Combine embeddings by concatenation\n",
        "    combined_embedding = np.concatenate((text_embedding, graph_embedding))\n",
        "\n",
        "    return combined_embedding\n",
        "\n",
        "# Prepare training data with negative samples\n",
        "train_data = []\n",
        "train_labels = []\n",
        "negative_samples = []\n",
        "negative_labels = []\n",
        "\n",
        "for _, row in substitution_pairs_df.iterrows():\n",
        "    ing1 = row['ingredient1']\n",
        "    ing2 = row['ingredient2']\n",
        "\n",
        "    combined_embedding1 = get_combined_embedding(ing1, model.wv, graph_embeddings)\n",
        "    combined_embedding2 = get_combined_embedding(ing2, model.wv, graph_embeddings)\n",
        "\n",
        "    train_data.append(combined_embedding1)\n",
        "    train_labels.append(combined_embedding2)\n",
        "\n",
        "    # Generate 500 negative samples by excluding valid substitutes\n",
        "    possible_negatives = [\n",
        "        ing for ing in ingredient_list\n",
        "        if ing != ing1 and ing not in valid_substitutes.get(ing1, set())\n",
        "    ]\n",
        "    selected_negatives = random.sample(possible_negatives, min(100, len(possible_negatives)))  # Pick 100 non-substitutes\n",
        "\n",
        "    for neg in selected_negatives:\n",
        "        neg_embedding = get_combined_embedding(neg, model.wv, graph_embeddings)\n",
        "        negative_labels.append(neg_embedding)\n",
        "        negative_samples.append(combined_embedding1)\n",
        "\n",
        "# Convert to tensors\n",
        "train_data = torch.tensor(train_data, dtype=torch.float32)\n",
        "train_labels = torch.tensor(train_labels, dtype=torch.float32)\n",
        "negative_samples = torch.tensor(negative_samples, dtype=torch.float32)\n",
        "negative_labels = torch.tensor(negative_labels, dtype=torch.float32)\n",
        "\n",
        "# Define the neural network\n",
        "class CombinedNN(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(CombinedNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, output_dim)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "nn_model = CombinedNN(input_dim=200, output_dim=200)  # Combined embedding dimension is 200 (100 + 100)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(nn_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop with negative sampling\n",
        "for epoch in range(300):\n",
        "    nn_model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Positive pair loss\n",
        "    outputs = nn_model(train_data)\n",
        "    loss = criterion(outputs, train_labels)\n",
        "\n",
        "    # Negative pair loss (contrastive or margin-based loss)\n",
        "    neg_outputs = nn_model(negative_samples)\n",
        "    expanded_outputs = outputs.repeat_interleave(100, dim=0)  # Ensure dimensions match for 100 negatives\n",
        "    negative_loss = torch.mean(torch.relu(1.0 - torch.sum(expanded_outputs * neg_outputs, dim=1)))\n",
        "\n",
        "    total_loss = loss + negative_loss\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Loss: {total_loss.item()}')\n",
        "\n",
        "# Validation\n",
        "val_data = []\n",
        "val_labels = []\n",
        "\n",
        "for _, row in substitution_pairs_df.iterrows():\n",
        "    if len(val_data) >= 500:\n",
        "        break\n",
        "    ing1 = row['ingredient1']\n",
        "    combined_embedding = get_combined_embedding(ing1, model.wv, graph_embeddings)\n",
        "\n",
        "    val_data.append(combined_embedding)\n",
        "    val_labels.append(row['ingredient2'])\n",
        "\n",
        "val_data = np.array(val_data)\n",
        "val_data = torch.tensor(val_data, dtype=torch.float32)\n",
        "val_predictions = nn_model(val_data).detach().numpy()\n",
        "\n",
        "# Function to find the top N most similar ingredients based on cosine similarity\n",
        "def find_top_similar_ingredients(predicted_embedding, combined_embeddings, top_n=10):\n",
        "    similarities = {}\n",
        "    for ingredient, embedding in combined_embeddings.items():\n",
        "        similarity = cosine_similarity(predicted_embedding.reshape(1, -1), embedding.reshape(1, -1))[0][0]\n",
        "        similarities[ingredient] = similarity\n",
        "    sorted_ingredients = sorted(similarities.items(), key=lambda item: item[1], reverse=True)\n",
        "    return [ingredient for ingredient, similarity in sorted_ingredients[:top_n]]\n",
        "\n",
        "# Function to calculate metrics with Jaro-Winkler similarity threshold\n",
        "def calculate_metrics(predictions, ground_truths, combined_embeddings, top_n=10, threshold=0.8):\n",
        "    mrr, hit_1, hit_3, hit_10 = 0.0, 0.0, 0.0, 0.0\n",
        "    total = len(ground_truths)\n",
        "\n",
        "    for pred, gt in zip(predictions, ground_truths):\n",
        "        top_similar = find_top_similar_ingredients(pred, combined_embeddings, top_n=top_n)\n",
        "        for rank, candidate in enumerate(top_similar, start=1):\n",
        "            sim = jellyfish.jaro_winkler_similarity(gt, candidate)\n",
        "            if sim >= threshold:\n",
        "                mrr += 1.0 / rank\n",
        "                if rank == 1:\n",
        "                    hit_1 += 1.0\n",
        "                if rank <= 3:\n",
        "                    hit_3 += 1.0\n",
        "                if rank <= 10:\n",
        "                    hit_10 += 1.0\n",
        "                break\n",
        "\n",
        "    mrr /= total\n",
        "    hit_1 /= total\n",
        "    hit_3 /= total\n",
        "    hit_10 /= total\n",
        "    return mrr, hit_1, hit_3, hit_10\n",
        "\n",
        "# Calculate metrics for the first 1000 entries of the validation set\n",
        "val_labels_str = val_labels  # Assuming labels are ingredient names\n",
        "combined_embeddings = {ingredient: get_combined_embedding(ingredient, model.wv, graph_embeddings) for ingredient in model.wv.index_to_key}\n",
        "\n",
        "mrr, hit_1, hit_3, hit_10 = calculate_metrics(val_predictions, val_labels_str, combined_embeddings)\n",
        "\n",
        "print(f\"MRR: {mrr:.4f}, Hit@1: {hit_1:.4f}, Hit@3: {hit_3:.4f}, Hit@10: {hit_10:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "49f3d50b7c50455aac5e86024599d26e",
            "effb15fb8fa74fa0a9b988b1684d8ece",
            "ac6ffe3dbc0e49509ce8d7871f23eaa0",
            "647ca0a50ca04acf998a6515db6303f2",
            "3258a2dd0f304f64a46794cef784c0c8",
            "b81b22c8629b4f5d90385f0e5858787d",
            "335a1aab17e14fa3966ce616cd7df730",
            "7850b43fa1ed4aa79b11e8ccadc3ec55",
            "b855b3ca30b1442d88b1fb7e3ebaf269",
            "f02bf9d71bcb456a9ec4d415d18ac036",
            "54818bf2a1f747afbc9a7326d746d21e"
          ]
        },
        "id": "-BRpcCHjDXc8",
        "outputId": "3c7e0acc-5d9b-4cf6-b9a0-0948b0086bd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49f3d50b7c50455aac5e86024599d26e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Computing transition probabilities:   0%|          | 0/6651 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-f1fe011d0c08>:138: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
            "  train_data = torch.tensor(train_data, dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.8221169710159302\n",
            "Epoch 2, Loss: 0.8052106499671936\n",
            "Epoch 3, Loss: 0.7907443642616272\n",
            "Epoch 4, Loss: 0.7783506512641907\n",
            "Epoch 5, Loss: 0.767662525177002\n",
            "Epoch 6, Loss: 0.7581714391708374\n",
            "Epoch 7, Loss: 0.7509445548057556\n",
            "Epoch 8, Loss: 0.7440974712371826\n",
            "Epoch 9, Loss: 0.7390084266662598\n",
            "Epoch 10, Loss: 0.7336133122444153\n",
            "Epoch 11, Loss: 0.7291702032089233\n",
            "Epoch 12, Loss: 0.725024402141571\n",
            "Epoch 13, Loss: 0.7213757038116455\n",
            "Epoch 14, Loss: 0.7177773714065552\n",
            "Epoch 15, Loss: 0.7149329781532288\n",
            "Epoch 16, Loss: 0.7119714021682739\n",
            "Epoch 17, Loss: 0.7091203927993774\n",
            "Epoch 18, Loss: 0.7065960168838501\n",
            "Epoch 19, Loss: 0.7040128707885742\n",
            "Epoch 20, Loss: 0.7017800211906433\n",
            "Epoch 21, Loss: 0.69927978515625\n",
            "Epoch 22, Loss: 0.6971295475959778\n",
            "Epoch 23, Loss: 0.6952140927314758\n",
            "Epoch 24, Loss: 0.6931967735290527\n",
            "Epoch 25, Loss: 0.6915526390075684\n",
            "Epoch 26, Loss: 0.6896356344223022\n",
            "Epoch 27, Loss: 0.688218355178833\n",
            "Epoch 28, Loss: 0.6866771578788757\n",
            "Epoch 29, Loss: 0.6853801608085632\n",
            "Epoch 30, Loss: 0.6834638714790344\n",
            "Epoch 31, Loss: 0.682686984539032\n",
            "Epoch 32, Loss: 0.6811904311180115\n",
            "Epoch 33, Loss: 0.6799722909927368\n",
            "Epoch 34, Loss: 0.6788628101348877\n",
            "Epoch 35, Loss: 0.6773719787597656\n",
            "Epoch 36, Loss: 0.6762998104095459\n",
            "Epoch 37, Loss: 0.6752700805664062\n",
            "Epoch 38, Loss: 0.6742745041847229\n",
            "Epoch 39, Loss: 0.6735411286354065\n",
            "Epoch 40, Loss: 0.6722425222396851\n",
            "Epoch 41, Loss: 0.6717394590377808\n",
            "Epoch 42, Loss: 0.670224666595459\n",
            "Epoch 43, Loss: 0.6696756482124329\n",
            "Epoch 44, Loss: 0.6690751910209656\n",
            "Epoch 45, Loss: 0.6683292984962463\n",
            "Epoch 46, Loss: 0.6673704981803894\n",
            "Epoch 47, Loss: 0.6664942502975464\n",
            "Epoch 48, Loss: 0.665251612663269\n",
            "Epoch 49, Loss: 0.6648654937744141\n",
            "Epoch 50, Loss: 0.6636665463447571\n",
            "Epoch 51, Loss: 0.6632620692253113\n",
            "Epoch 52, Loss: 0.6624820828437805\n",
            "Epoch 53, Loss: 0.661534309387207\n",
            "Epoch 54, Loss: 0.6612112522125244\n",
            "Epoch 55, Loss: 0.6598832607269287\n",
            "Epoch 56, Loss: 0.659976065158844\n",
            "Epoch 57, Loss: 0.6594736576080322\n",
            "Epoch 58, Loss: 0.6585475206375122\n",
            "Epoch 59, Loss: 0.6577326059341431\n",
            "Epoch 60, Loss: 0.6570989489555359\n",
            "Epoch 61, Loss: 0.6563477516174316\n",
            "Epoch 62, Loss: 0.6562405228614807\n",
            "Epoch 63, Loss: 0.6552472710609436\n",
            "Epoch 64, Loss: 0.6551650166511536\n",
            "Epoch 65, Loss: 0.654407262802124\n",
            "Epoch 66, Loss: 0.6536946296691895\n",
            "Epoch 67, Loss: 0.6530357003211975\n",
            "Epoch 68, Loss: 0.6524544954299927\n",
            "Epoch 69, Loss: 0.6521114110946655\n",
            "Epoch 70, Loss: 0.6520761251449585\n",
            "Epoch 71, Loss: 0.6514819860458374\n",
            "Epoch 72, Loss: 0.6510938405990601\n",
            "Epoch 73, Loss: 0.6503623723983765\n",
            "Epoch 74, Loss: 0.6504311561584473\n",
            "Epoch 75, Loss: 0.6497066020965576\n",
            "Epoch 76, Loss: 0.6492053270339966\n",
            "Epoch 77, Loss: 0.6487995982170105\n",
            "Epoch 78, Loss: 0.6480389833450317\n",
            "Epoch 79, Loss: 0.647788941860199\n",
            "Epoch 80, Loss: 0.6474075317382812\n",
            "Epoch 81, Loss: 0.6470987796783447\n",
            "Epoch 82, Loss: 0.646752655506134\n",
            "Epoch 83, Loss: 0.6466223001480103\n",
            "Epoch 84, Loss: 0.645904004573822\n",
            "Epoch 85, Loss: 0.6454948782920837\n",
            "Epoch 86, Loss: 0.6450208425521851\n",
            "Epoch 87, Loss: 0.644936740398407\n",
            "Epoch 88, Loss: 0.6449238657951355\n",
            "Epoch 89, Loss: 0.6444030404090881\n",
            "Epoch 90, Loss: 0.6438742280006409\n",
            "Epoch 91, Loss: 0.6436614394187927\n",
            "Epoch 92, Loss: 0.6437763571739197\n",
            "Epoch 93, Loss: 0.6427930593490601\n",
            "Epoch 94, Loss: 0.6428558826446533\n",
            "Epoch 95, Loss: 0.6425605416297913\n",
            "Epoch 96, Loss: 0.6423726677894592\n",
            "Epoch 97, Loss: 0.6416525840759277\n",
            "Epoch 98, Loss: 0.642141580581665\n",
            "Epoch 99, Loss: 0.6413959860801697\n",
            "Epoch 100, Loss: 0.6411626935005188\n",
            "Epoch 101, Loss: 0.6403293609619141\n",
            "Epoch 102, Loss: 0.6403759717941284\n",
            "Epoch 103, Loss: 0.6409099698066711\n",
            "Epoch 104, Loss: 0.6403589248657227\n",
            "Epoch 105, Loss: 0.6400155425071716\n",
            "Epoch 106, Loss: 0.6392156481742859\n",
            "Epoch 107, Loss: 0.6398031115531921\n",
            "Epoch 108, Loss: 0.6388588547706604\n",
            "Epoch 109, Loss: 0.638638973236084\n",
            "Epoch 110, Loss: 0.6386431455612183\n",
            "Epoch 111, Loss: 0.6387696266174316\n",
            "Epoch 112, Loss: 0.6384049654006958\n",
            "Epoch 113, Loss: 0.6385073065757751\n",
            "Epoch 114, Loss: 0.6379603147506714\n",
            "Epoch 115, Loss: 0.6373929381370544\n",
            "Epoch 116, Loss: 0.6372997760772705\n",
            "Epoch 117, Loss: 0.637673020362854\n",
            "Epoch 118, Loss: 0.6372131109237671\n",
            "Epoch 119, Loss: 0.6368762254714966\n",
            "Epoch 120, Loss: 0.6370785236358643\n",
            "Epoch 121, Loss: 0.6368422508239746\n",
            "Epoch 122, Loss: 0.6361662745475769\n",
            "Epoch 123, Loss: 0.6359580755233765\n",
            "Epoch 124, Loss: 0.6350153684616089\n",
            "Epoch 125, Loss: 0.6362238526344299\n",
            "Epoch 126, Loss: 0.6362238526344299\n",
            "Epoch 127, Loss: 0.6356446146965027\n",
            "Epoch 128, Loss: 0.6347946524620056\n",
            "Epoch 129, Loss: 0.6352390646934509\n",
            "Epoch 130, Loss: 0.6351614594459534\n",
            "Epoch 131, Loss: 0.6348451972007751\n",
            "Epoch 132, Loss: 0.6341391801834106\n",
            "Epoch 133, Loss: 0.634640634059906\n",
            "Epoch 134, Loss: 0.6349961161613464\n",
            "Epoch 135, Loss: 0.6339834928512573\n",
            "Epoch 136, Loss: 0.633767306804657\n",
            "Epoch 137, Loss: 0.634049117565155\n",
            "Epoch 138, Loss: 0.6336880326271057\n",
            "Epoch 139, Loss: 0.633640468120575\n",
            "Epoch 140, Loss: 0.63302081823349\n",
            "Epoch 141, Loss: 0.6332257986068726\n",
            "Epoch 142, Loss: 0.6335519552230835\n",
            "Epoch 143, Loss: 0.6330366730690002\n",
            "Epoch 144, Loss: 0.6332619190216064\n",
            "Epoch 145, Loss: 0.6327182650566101\n",
            "Epoch 146, Loss: 0.632781445980072\n",
            "Epoch 147, Loss: 0.6325400471687317\n",
            "Epoch 148, Loss: 0.6325264573097229\n",
            "Epoch 149, Loss: 0.6323910355567932\n",
            "Epoch 150, Loss: 0.631933331489563\n",
            "Epoch 151, Loss: 0.6315155625343323\n",
            "Epoch 152, Loss: 0.6317567825317383\n",
            "Epoch 153, Loss: 0.6321107149124146\n",
            "Epoch 154, Loss: 0.6314404010772705\n",
            "Epoch 155, Loss: 0.6316598653793335\n",
            "Epoch 156, Loss: 0.6313669681549072\n",
            "Epoch 157, Loss: 0.6316484212875366\n",
            "Epoch 158, Loss: 0.6313720345497131\n",
            "Epoch 159, Loss: 0.6314483880996704\n",
            "Epoch 160, Loss: 0.6310071349143982\n",
            "Epoch 161, Loss: 0.6307981014251709\n",
            "Epoch 162, Loss: 0.6307883262634277\n",
            "Epoch 163, Loss: 0.6313197016716003\n",
            "Epoch 164, Loss: 0.6311023831367493\n",
            "Epoch 165, Loss: 0.6304886341094971\n",
            "Epoch 166, Loss: 0.6304886937141418\n",
            "Epoch 167, Loss: 0.6301688551902771\n",
            "Epoch 168, Loss: 0.629939615726471\n",
            "Epoch 169, Loss: 0.6302046775817871\n",
            "Epoch 170, Loss: 0.6297250390052795\n",
            "Epoch 171, Loss: 0.6301735043525696\n",
            "Epoch 172, Loss: 0.6294949650764465\n",
            "Epoch 173, Loss: 0.6300963759422302\n",
            "Epoch 174, Loss: 0.6299742460250854\n",
            "Epoch 175, Loss: 0.629882276058197\n",
            "Epoch 176, Loss: 0.6297311782836914\n",
            "Epoch 177, Loss: 0.6300165057182312\n",
            "Epoch 178, Loss: 0.6296010613441467\n",
            "Epoch 179, Loss: 0.6295003890991211\n",
            "Epoch 180, Loss: 0.6295074224472046\n",
            "Epoch 181, Loss: 0.6295071244239807\n",
            "Epoch 182, Loss: 0.6286245584487915\n",
            "Epoch 183, Loss: 0.6284556984901428\n",
            "Epoch 184, Loss: 0.6292641162872314\n",
            "Epoch 185, Loss: 0.6282902359962463\n",
            "Epoch 186, Loss: 0.6282578110694885\n",
            "Epoch 187, Loss: 0.6288410425186157\n",
            "Epoch 188, Loss: 0.6287209987640381\n",
            "Epoch 189, Loss: 0.6289188861846924\n",
            "Epoch 190, Loss: 0.628603994846344\n",
            "Epoch 191, Loss: 0.6281519532203674\n",
            "Epoch 192, Loss: 0.6281912922859192\n",
            "Epoch 193, Loss: 0.6282023191452026\n",
            "Epoch 194, Loss: 0.6282944679260254\n",
            "Epoch 195, Loss: 0.6283709406852722\n",
            "Epoch 196, Loss: 0.6282714605331421\n",
            "Epoch 197, Loss: 0.6283777356147766\n",
            "Epoch 198, Loss: 0.6277879476547241\n",
            "Epoch 199, Loss: 0.6276102066040039\n",
            "Epoch 200, Loss: 0.6276452541351318\n",
            "Epoch 201, Loss: 0.627316415309906\n",
            "Epoch 202, Loss: 0.6272518038749695\n",
            "Epoch 203, Loss: 0.6273854970932007\n",
            "Epoch 204, Loss: 0.6273106932640076\n",
            "Epoch 205, Loss: 0.6275395750999451\n",
            "Epoch 206, Loss: 0.6277241110801697\n",
            "Epoch 207, Loss: 0.6274887919425964\n",
            "Epoch 208, Loss: 0.6264804005622864\n",
            "Epoch 209, Loss: 0.6266067028045654\n",
            "Epoch 210, Loss: 0.6274821758270264\n",
            "Epoch 211, Loss: 0.626960813999176\n",
            "Epoch 212, Loss: 0.6266441941261292\n",
            "Epoch 213, Loss: 0.6269364356994629\n",
            "Epoch 214, Loss: 0.6277326345443726\n",
            "Epoch 215, Loss: 0.6271138191223145\n",
            "Epoch 216, Loss: 0.626133143901825\n",
            "Epoch 217, Loss: 0.6270270943641663\n",
            "Epoch 218, Loss: 0.6261530518531799\n",
            "Epoch 219, Loss: 0.6264956593513489\n",
            "Epoch 220, Loss: 0.6269642114639282\n",
            "Epoch 221, Loss: 0.6263537406921387\n",
            "Epoch 222, Loss: 0.626147449016571\n",
            "Epoch 223, Loss: 0.6266149282455444\n",
            "Epoch 224, Loss: 0.6266640424728394\n",
            "Epoch 225, Loss: 0.6263595819473267\n",
            "Epoch 226, Loss: 0.6258469223976135\n",
            "Epoch 227, Loss: 0.6262343525886536\n",
            "Epoch 228, Loss: 0.6255391240119934\n",
            "Epoch 229, Loss: 0.6258734464645386\n",
            "Epoch 230, Loss: 0.6258455514907837\n",
            "Epoch 231, Loss: 0.6255263090133667\n",
            "Epoch 232, Loss: 0.625747561454773\n",
            "Epoch 233, Loss: 0.6261000037193298\n",
            "Epoch 234, Loss: 0.6255188584327698\n",
            "Epoch 235, Loss: 0.6258507370948792\n",
            "Epoch 236, Loss: 0.6253859400749207\n",
            "Epoch 237, Loss: 0.6253486275672913\n",
            "Epoch 238, Loss: 0.6251445412635803\n",
            "Epoch 239, Loss: 0.6263490915298462\n",
            "Epoch 240, Loss: 0.6257805824279785\n",
            "Epoch 241, Loss: 0.6259249448776245\n",
            "Epoch 242, Loss: 0.6250791549682617\n",
            "Epoch 243, Loss: 0.6253314018249512\n",
            "Epoch 244, Loss: 0.6251781582832336\n",
            "Epoch 245, Loss: 0.6253453493118286\n",
            "Epoch 246, Loss: 0.6251134872436523\n",
            "Epoch 247, Loss: 0.6256685256958008\n",
            "Epoch 248, Loss: 0.6249107718467712\n",
            "Epoch 249, Loss: 0.6253407001495361\n",
            "Epoch 250, Loss: 0.6254332065582275\n",
            "Epoch 251, Loss: 0.6252959370613098\n",
            "Epoch 252, Loss: 0.6250492930412292\n",
            "Epoch 253, Loss: 0.6253026127815247\n",
            "Epoch 254, Loss: 0.6249492168426514\n",
            "Epoch 255, Loss: 0.6244397163391113\n",
            "Epoch 256, Loss: 0.6246822476387024\n",
            "Epoch 257, Loss: 0.6249433755874634\n",
            "Epoch 258, Loss: 0.6241350769996643\n",
            "Epoch 259, Loss: 0.6244422197341919\n",
            "Epoch 260, Loss: 0.6241707801818848\n",
            "Epoch 261, Loss: 0.6247918605804443\n",
            "Epoch 262, Loss: 0.6246609091758728\n",
            "Epoch 263, Loss: 0.6248390674591064\n",
            "Epoch 264, Loss: 0.6244742274284363\n",
            "Epoch 265, Loss: 0.6238747239112854\n",
            "Epoch 266, Loss: 0.6245685815811157\n",
            "Epoch 267, Loss: 0.6245947480201721\n",
            "Epoch 268, Loss: 0.624873161315918\n",
            "Epoch 269, Loss: 0.6248191595077515\n",
            "Epoch 270, Loss: 0.6242094039916992\n",
            "Epoch 271, Loss: 0.6237822771072388\n",
            "Epoch 272, Loss: 0.6241207718849182\n",
            "Epoch 273, Loss: 0.6239731907844543\n",
            "Epoch 274, Loss: 0.6240060329437256\n",
            "Epoch 275, Loss: 0.6239309310913086\n",
            "Epoch 276, Loss: 0.6240898966789246\n",
            "Epoch 277, Loss: 0.6244016289710999\n",
            "Epoch 278, Loss: 0.6242156624794006\n",
            "Epoch 279, Loss: 0.6241600513458252\n",
            "Epoch 280, Loss: 0.6238513588905334\n",
            "Epoch 281, Loss: 0.6238197684288025\n",
            "Epoch 282, Loss: 0.6238046288490295\n",
            "Epoch 283, Loss: 0.6230983138084412\n",
            "Epoch 284, Loss: 0.6238065361976624\n",
            "Epoch 285, Loss: 0.6240401864051819\n",
            "Epoch 286, Loss: 0.6235632300376892\n",
            "Epoch 287, Loss: 0.6236506104469299\n",
            "Epoch 288, Loss: 0.6232220530509949\n",
            "Epoch 289, Loss: 0.6232731342315674\n",
            "Epoch 290, Loss: 0.6232369542121887\n",
            "Epoch 291, Loss: 0.6239593625068665\n",
            "Epoch 292, Loss: 0.623595118522644\n",
            "Epoch 293, Loss: 0.623405396938324\n",
            "Epoch 294, Loss: 0.6231631636619568\n",
            "Epoch 295, Loss: 0.6232713460922241\n",
            "Epoch 296, Loss: 0.623469889163971\n",
            "Epoch 297, Loss: 0.6233661770820618\n",
            "Epoch 298, Loss: 0.6224929094314575\n",
            "Epoch 299, Loss: 0.6233725547790527\n",
            "Epoch 300, Loss: 0.6227324604988098\n",
            "MRR: 0.1509, Hit@1: 0.0960, Hit@3: 0.1740, Hit@10: 0.2940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Word2Vec model\n",
        "model.save(\"/content/drive/My Drive/ERP/MODEL_BEST_NUMBERS/word2vec_model.model\")\n",
        "\n",
        "# Save the neural network model\n",
        "torch.save(nn_model.state_dict(), \"/content/drive/My Drive/ERP/MODEL_BEST_NUMBERS/nn_model.pth\")\n",
        "\n",
        "# Save graph embeddings\n",
        "import pickle\n",
        "with open(\"/content/drive/My Drive/ERP/MODEL_BEST_NUMBERS/graph_embeddings.pkl\", \"wb\") as f:\n",
        "    pickle.dump(graph_embeddings, f)\n",
        "\n",
        "print(\"Models saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS-uPV1krKay",
        "outputId": "edba699f-9d94-4a9e-8267-73a330283849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models saved successfully!\n"
          ]
        }
      ]
    }
  ]
}