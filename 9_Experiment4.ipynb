{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "7b893cBAMxRM",
        "JYDHPAzfM89o",
        "-tpdS4R4NFyG",
        "OnENOsAqNdii",
        "OHeMjgnyNZWg"
      ],
      "authorship_tag": "ABX9TyPwdH47YEsCE4JJ90m9/+02",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9dab20699b834cadb726a670ad94f4ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6304f14c247a48118a6906860f2f0f59",
              "IPY_MODEL_7506dbcfaeed4a1ea1ead59be5286bec",
              "IPY_MODEL_6a19d668ea644759bc3375f0c369b9c4"
            ],
            "layout": "IPY_MODEL_cdecdc0e6bbb474cbcc9fda693d914ce"
          }
        },
        "6304f14c247a48118a6906860f2f0f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a63d1c4ae5f04717817b818504903d7f",
            "placeholder": "​",
            "style": "IPY_MODEL_6c2967fbab6f44a18652119994c9bac0",
            "value": "Computing transition probabilities: 100%"
          }
        },
        "7506dbcfaeed4a1ea1ead59be5286bec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34df08660f0e44cd9dbe29b3b896cb02",
            "max": 6651,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_910ba991b2954738973939820eb7b3ef",
            "value": 6651
          }
        },
        "6a19d668ea644759bc3375f0c369b9c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18332acd81574bae91b6000688c98df2",
            "placeholder": "​",
            "style": "IPY_MODEL_e38ac971b90e4ceea7d6a1946714705d",
            "value": " 6651/6651 [06:31&lt;00:00, 13.69it/s]"
          }
        },
        "cdecdc0e6bbb474cbcc9fda693d914ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a63d1c4ae5f04717817b818504903d7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c2967fbab6f44a18652119994c9bac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34df08660f0e44cd9dbe29b3b896cb02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "910ba991b2954738973939820eb7b3ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18332acd81574bae91b6000688c98df2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e38ac971b90e4ceea7d6a1946714705d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JITHIN-ANTONY-JOSEPH/ERP_11358080/blob/main/9_Experiment4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input : Recipe Instructions\n",
        "### Model : Word2Vec(Text) + Node2Vec(Graph) + Neural Networks(Model)"
      ],
      "metadata": {
        "id": "iguW8GTnaFt-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mounting to connect to Google Drive"
      ],
      "metadata": {
        "id": "7b893cBAMxRM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3RMueg-Fgbo",
        "outputId": "34aa7307-bc9f-46d0-b783-cf16eae783fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing required libraries"
      ],
      "metadata": {
        "id": "JYDHPAzfM89o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install node2vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNoHd2KrISPx",
        "outputId": "8286ef55-8241-4e9b-964f-780f080d0dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting node2vec\n",
            "  Downloading node2vec-0.5.0-py3-none-any.whl.metadata (849 bytes)\n",
            "Requirement already satisfied: gensim<5.0.0,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from node2vec) (4.3.3)\n",
            "Requirement already satisfied: joblib<2.0.0,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from node2vec) (1.4.2)\n",
            "Requirement already satisfied: networkx<4.0.0,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from node2vec) (3.3)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from node2vec) (1.26.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from node2vec) (4.66.5)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.0->node2vec) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim<5.0.0,>=4.3.0->node2vec) (7.0.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim<5.0.0,>=4.3.0->node2vec) (1.16.0)\n",
            "Downloading node2vec-0.5.0-py3-none-any.whl (7.2 kB)\n",
            "Installing collected packages: node2vec\n",
            "Successfully installed node2vec-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing libraries and required datasets"
      ],
      "metadata": {
        "id": "g3B19LaAM0uq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "V0KfNME9Fxjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flavorgraph_df = pd.read_csv('/content/drive/My Drive/ERP/Dataset/nodes_191120.csv')  # Adjust the path as needed , this is the path to my personal Google Drive"
      ],
      "metadata": {
        "id": "PBNmm2oYF6m5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "import jellyfish\n",
        "from gensim.models import Word2Vec\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "\n",
        "# Load the main dataset\n",
        "with open('/content/drive/My Drive/ERP/modified_Processed_Layer1.json', 'r') as file: # Adjust the path as needed , this is the path to my personal Google Drive\n",
        "    recipe1m_data = [json.loads(line) for line in file]\n",
        "\n",
        "recipe1m_df = pd.DataFrame(recipe1m_data)\n",
        "\n",
        "# Load the substitution pairs\n",
        "substitution_pairs_df = pd.read_csv('/content/drive/My Drive/ERP/Recipe1MSubs_full.csv') # Adjust the path as needed , this is the path to my personal Google Drive\n",
        "\n",
        "# Merge the datasets based on recipe_id (substitution_pairs_df) and id (recipe1m_df)\n",
        "merged_df = pd.merge(recipe1m_df, substitution_pairs_df, left_on='id', right_on='recipe_id')\n",
        "\n",
        "# Example ingredient list for NER-like extraction (replace with your own comprehensive list or use NER model)\n",
        "ingredient_list = set(flavorgraph_df[flavorgraph_df['node_type'] == 'ingredient']['name'].dropna().unique())\n",
        "\n",
        "# Function to extract ingredients from instructions\n",
        "def extract_ingredients_from_instructions(instructions, ingredient_list):\n",
        "    extracted_ingredients = []\n",
        "    for instruction in instructions:\n",
        "        words = instruction.split()\n",
        "        for word in words:\n",
        "            if word in ingredient_list:\n",
        "                extracted_ingredients.append(word)\n",
        "    return extracted_ingredients\n",
        "\n",
        "# Apply the extraction function\n",
        "recipe1m_df['extracted_ingredients'] = recipe1m_df['processed_instructions'].apply(\n",
        "    lambda instructions: extract_ingredients_from_instructions(instructions, ingredient_list) if isinstance(instructions, list) else []\n",
        ")\n",
        "\n",
        "# Prepare sentences for training\n",
        "sentences = recipe1m_df['extracted_ingredients'].tolist()\n",
        "\n",
        "# Add substitution contexts to sentences\n",
        "for _, row in substitution_pairs_df.iterrows():\n",
        "    ingredient1 = row['ingredient1']\n",
        "    ingredient2 = row['ingredient2']\n",
        "    sentences.append([ingredient1, ingredient2])\n",
        "\n",
        "# Train the Word2Vec model\n",
        "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=8)  # Increase 'workers' to utilize more CPU cores"
      ],
      "metadata": {
        "id": "FEqKlaW7GCap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "from node2vec import Node2Vec\n",
        "\n",
        "# Load the knowledge graph\n",
        "flavor_graph = nx.read_graphml('/content/drive/My Drive/ERP/knowledge_graph.graphml')\n",
        "\n",
        "# Filter the graph to include only ingredient nodes\n",
        "ingredient_nodes = [n for n, attr in flavor_graph.nodes(data=True) if attr['node_type'] == 'ingredient']\n",
        "flavor_graph = flavor_graph.subgraph(ingredient_nodes)\n",
        "\n",
        "# Generate Node2Vec embeddings considering edge weights\n",
        "node2vec = Node2Vec(flavor_graph, dimensions=100, walk_length=30, num_walks=200, workers=4, weight_key='weight')\n",
        "graph_model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
        "\n",
        "# Generate graph embeddings for the ingredients\n",
        "graph_embeddings = {str(node): graph_model.wv[str(node)] for node in flavor_graph.nodes()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9dab20699b834cadb726a670ad94f4ab",
            "6304f14c247a48118a6906860f2f0f59",
            "7506dbcfaeed4a1ea1ead59be5286bec",
            "6a19d668ea644759bc3375f0c369b9c4",
            "cdecdc0e6bbb474cbcc9fda693d914ce",
            "a63d1c4ae5f04717817b818504903d7f",
            "6c2967fbab6f44a18652119994c9bac0",
            "34df08660f0e44cd9dbe29b3b896cb02",
            "910ba991b2954738973939820eb7b3ef",
            "18332acd81574bae91b6000688c98df2",
            "e38ac971b90e4ceea7d6a1946714705d"
          ]
        },
        "id": "j6h3SbwjHn-K",
        "outputId": "a85c18b8-60a8-4f19-c1f7-ee1985395f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Computing transition probabilities:   0%|          | 0/6651 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9dab20699b834cadb726a670ad94f4ab"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to generate combined emedding"
      ],
      "metadata": {
        "id": "-tpdS4R4NFyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_combined_embedding(ingredient, text_embeddings, graph_embeddings):\n",
        "    # Get text embedding\n",
        "    if ingredient in text_embeddings:\n",
        "        text_embedding = text_embeddings[ingredient]\n",
        "    else:\n",
        "        text_embedding = np.zeros(100)\n",
        "\n",
        "    # Get graph embedding\n",
        "    if ingredient in graph_embeddings:\n",
        "        graph_embedding = graph_embeddings[ingredient]\n",
        "    else:\n",
        "        graph_embedding = np.zeros(100)\n",
        "\n",
        "    # Combine embeddings by concatenation\n",
        "    combined_embedding = np.concatenate((text_embedding, graph_embedding))\n",
        "\n",
        "    return combined_embedding"
      ],
      "metadata": {
        "id": "WSCBl4-1IlNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Combine embeddings for training data\n",
        "train_data = []\n",
        "train_labels = []\n",
        "\n",
        "for _, row in substitution_pairs_df.iterrows():\n",
        "    ing1 = row['ingredient1']\n",
        "    ing2 = row['ingredient2']\n",
        "    combined_embedding1 = get_combined_embedding(ing1, model.wv, graph_embeddings)\n",
        "    combined_embedding2 = get_combined_embedding(ing2, model.wv, graph_embeddings)\n",
        "\n",
        "    train_data.append(combined_embedding1)\n",
        "    train_labels.append(combined_embedding2)\n",
        "\n",
        "train_data = torch.tensor(train_data, dtype=torch.float32)\n",
        "train_labels = torch.tensor(train_labels, dtype=torch.float32)\n",
        "\n",
        "# Define the neural network\n",
        "class CombinedNN(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(CombinedNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, output_dim)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "nn_model = CombinedNN(input_dim=200, output_dim=200)  # Combined embedding dimension is 200 (100 + 100)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(nn_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(100):\n",
        "    nn_model.train()\n",
        "    optimizer.zero_grad()\n",
        "    outputs = nn_model(train_data)\n",
        "    loss = criterion(outputs, train_labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
        "\n",
        "# Evaluate on validation set\n",
        "val_data = []\n",
        "val_labels = []\n",
        "\n",
        "for _, row in substitution_pairs_df.iterrows():\n",
        "    ing1 = row['ingredient1']\n",
        "    combined_embedding = get_combined_embedding(ing1, model.wv, graph_embeddings)\n",
        "\n",
        "    val_data.append(combined_embedding)\n",
        "    val_labels.append(row['ingredient2'])\n",
        "\n",
        "val_data = torch.tensor(val_data, dtype=torch.float32)\n",
        "val_predictions = nn_model(val_data).detach().numpy()\n",
        "\n",
        "# Calculate metrics\n",
        "def calculate_metrics(predictions, ground_truths, threshold=0.8):\n",
        "    mrr, hit_1, hit_3, hit_10 = 0.0, 0.0, 0.0, 0.0\n",
        "    total = len(ground_truths)\n",
        "\n",
        "    for pred, gt in zip(predictions, ground_truths):\n",
        "        for i, candidate in enumerate(pred):\n",
        "            sim = jellyfish.jaro_winkler_similarity(gt, candidate)\n",
        "            if sim >= threshold:\n",
        "                rank = i + 1\n",
        "                mrr += 1.0 / rank\n",
        "                if rank == 1:\n",
        "                    hit_1 += 1.0\n",
        "                if rank <= 3:\n",
        "                    hit_3 += 1.0\n",
        "                if rank <= 10:\n",
        "                    hit_10 += 1.0\n",
        "                break\n",
        "\n",
        "    mrr /= total\n",
        "    hit_1 /= total\n",
        "    hit_3 /= total\n",
        "    hit_10 /= total\n",
        "    return mrr, hit_1, hit_3, hit_10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qKsV1xFQMx1a",
        "outputId": "e09e5292-0be9-4104-e75a-90cf99867a78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.814375102519989\n",
            "Epoch 2, Loss: 0.7964789271354675\n",
            "Epoch 3, Loss: 0.7819646596908569\n",
            "Epoch 4, Loss: 0.7702195644378662\n",
            "Epoch 5, Loss: 0.7602139115333557\n",
            "Epoch 6, Loss: 0.7524577379226685\n",
            "Epoch 7, Loss: 0.7456110119819641\n",
            "Epoch 8, Loss: 0.7398830652236938\n",
            "Epoch 9, Loss: 0.7348960638046265\n",
            "Epoch 10, Loss: 0.7304099202156067\n",
            "Epoch 11, Loss: 0.7265001535415649\n",
            "Epoch 12, Loss: 0.7229229807853699\n",
            "Epoch 13, Loss: 0.7197195887565613\n",
            "Epoch 14, Loss: 0.7165138125419617\n",
            "Epoch 15, Loss: 0.7138001918792725\n",
            "Epoch 16, Loss: 0.7110681533813477\n",
            "Epoch 17, Loss: 0.7085040211677551\n",
            "Epoch 18, Loss: 0.7059227824211121\n",
            "Epoch 19, Loss: 0.7036224007606506\n",
            "Epoch 20, Loss: 0.701583743095398\n",
            "Epoch 21, Loss: 0.6996977925300598\n",
            "Epoch 22, Loss: 0.6976271271705627\n",
            "Epoch 23, Loss: 0.6957341432571411\n",
            "Epoch 24, Loss: 0.6936877369880676\n",
            "Epoch 25, Loss: 0.6916800141334534\n",
            "Epoch 26, Loss: 0.6901131272315979\n",
            "Epoch 27, Loss: 0.6883444786071777\n",
            "Epoch 28, Loss: 0.6868767142295837\n",
            "Epoch 29, Loss: 0.6858054399490356\n",
            "Epoch 30, Loss: 0.6839593648910522\n",
            "Epoch 31, Loss: 0.6826224327087402\n",
            "Epoch 32, Loss: 0.6809224486351013\n",
            "Epoch 33, Loss: 0.6796239018440247\n",
            "Epoch 34, Loss: 0.6789011359214783\n",
            "Epoch 35, Loss: 0.6774402856826782\n",
            "Epoch 36, Loss: 0.6764823794364929\n",
            "Epoch 37, Loss: 0.6750657558441162\n",
            "Epoch 38, Loss: 0.6736245155334473\n",
            "Epoch 39, Loss: 0.6728984117507935\n",
            "Epoch 40, Loss: 0.6719678640365601\n",
            "Epoch 41, Loss: 0.670991063117981\n",
            "Epoch 42, Loss: 0.6699017286300659\n",
            "Epoch 43, Loss: 0.6691106557846069\n",
            "Epoch 44, Loss: 0.66814786195755\n",
            "Epoch 45, Loss: 0.6672131419181824\n",
            "Epoch 46, Loss: 0.6664785742759705\n",
            "Epoch 47, Loss: 0.6651611924171448\n",
            "Epoch 48, Loss: 0.6646398305892944\n",
            "Epoch 49, Loss: 0.6635918021202087\n",
            "Epoch 50, Loss: 0.6628351211547852\n",
            "Epoch 51, Loss: 0.6623457670211792\n",
            "Epoch 52, Loss: 0.6614711284637451\n",
            "Epoch 53, Loss: 0.6608651280403137\n",
            "Epoch 54, Loss: 0.6602118611335754\n",
            "Epoch 55, Loss: 0.6595447063446045\n",
            "Epoch 56, Loss: 0.6586626172065735\n",
            "Epoch 57, Loss: 0.6581480503082275\n",
            "Epoch 58, Loss: 0.6572010517120361\n",
            "Epoch 59, Loss: 0.6568847298622131\n",
            "Epoch 60, Loss: 0.6558114290237427\n",
            "Epoch 61, Loss: 0.655930757522583\n",
            "Epoch 62, Loss: 0.6549972295761108\n",
            "Epoch 63, Loss: 0.6543019413948059\n",
            "Epoch 64, Loss: 0.6538082957267761\n",
            "Epoch 65, Loss: 0.6536273956298828\n",
            "Epoch 66, Loss: 0.6528081297874451\n",
            "Epoch 67, Loss: 0.6518828272819519\n",
            "Epoch 68, Loss: 0.6522974371910095\n",
            "Epoch 69, Loss: 0.6511951088905334\n",
            "Epoch 70, Loss: 0.650588870048523\n",
            "Epoch 71, Loss: 0.650591254234314\n",
            "Epoch 72, Loss: 0.6495742201805115\n",
            "Epoch 73, Loss: 0.6494318842887878\n",
            "Epoch 74, Loss: 0.6491085290908813\n",
            "Epoch 75, Loss: 0.648987352848053\n",
            "Epoch 76, Loss: 0.647957980632782\n",
            "Epoch 77, Loss: 0.6475001573562622\n",
            "Epoch 78, Loss: 0.6475418210029602\n",
            "Epoch 79, Loss: 0.6470469236373901\n",
            "Epoch 80, Loss: 0.6464865803718567\n",
            "Epoch 81, Loss: 0.64625084400177\n",
            "Epoch 82, Loss: 0.6460093259811401\n",
            "Epoch 83, Loss: 0.6460617780685425\n",
            "Epoch 84, Loss: 0.6452957987785339\n",
            "Epoch 85, Loss: 0.6450336575508118\n",
            "Epoch 86, Loss: 0.6448966264724731\n",
            "Epoch 87, Loss: 0.6441485285758972\n",
            "Epoch 88, Loss: 0.6442440152168274\n",
            "Epoch 89, Loss: 0.6432610154151917\n",
            "Epoch 90, Loss: 0.6432846784591675\n",
            "Epoch 91, Loss: 0.6427326798439026\n",
            "Epoch 92, Loss: 0.6424735188484192\n",
            "Epoch 93, Loss: 0.6423364877700806\n",
            "Epoch 94, Loss: 0.642041027545929\n",
            "Epoch 95, Loss: 0.642003059387207\n",
            "Epoch 96, Loss: 0.6416276693344116\n",
            "Epoch 97, Loss: 0.6414154171943665\n",
            "Epoch 98, Loss: 0.6409565806388855\n",
            "Epoch 99, Loss: 0.6408010721206665\n",
            "Epoch 100, Loss: 0.6405351161956787\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ingredient_embeddings' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-5f07aa984b9a>\u001b[0m in \u001b[0;36m<cell line: 92>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0mval_labels_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Assuming labels are ingredient names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0mval_predictions_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mingredient_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_predictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0mmrr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhit_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhit_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhit_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_predictions_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-5f07aa984b9a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0mval_labels_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Assuming labels are ingredient names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0mval_predictions_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mingredient_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_predictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0mmrr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhit_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhit_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhit_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_predictions_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ingredient_embeddings' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Tests (Can be ignored)"
      ],
      "metadata": {
        "id": "OnENOsAqNdii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "beef_embedding = get_combined_embedding('sugar', model.wv, graph_embeddings)\n",
        "beef_embedding_tensor = torch.tensor(beef_embedding, dtype=torch.float32).unsqueeze(0)  # Add batch dimension\n",
        "predicted_embedding = nn_model(beef_embedding_tensor).detach().numpy().squeeze()\n"
      ],
      "metadata": {
        "id": "HXoqMf2DSPKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Combine text and graph embeddings for all ingredients\n",
        "combined_embeddings = {ingredient: get_combined_embedding(ingredient, model.wv, graph_embeddings) for ingredient in model.wv.index_to_key}\n",
        "\n",
        "# Function to find the top 10 most similar ingredients based on cosine similarity\n",
        "def find_top_similar_ingredients(predicted_embedding, combined_embeddings, top_n=10):\n",
        "    similarities = {}\n",
        "    for ingredient, embedding in combined_embeddings.items():\n",
        "        similarity = cosine_similarity(predicted_embedding.reshape(1, -1), embedding.reshape(1, -1))[0][0]\n",
        "        similarities[ingredient] = similarity\n",
        "    sorted_ingredients = sorted(similarities.items(), key=lambda item: item[1], reverse=True)\n",
        "    return sorted_ingredients[:top_n]\n",
        "\n",
        "# Find the top 10 most similar ingredients to the predicted embedding\n",
        "top_similar_ingredients = find_top_similar_ingredients(predicted_embedding, combined_embeddings, top_n=10)\n",
        "\n",
        "print(f\"Top 10 substitutions for 'beef':\")\n",
        "for ingredient, similarity in top_similar_ingredients:\n",
        "    print(f\"{ingredient}: {similarity:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYQR-l43SSES",
        "outputId": "e6109b02-e55a-47a0-a6c7-1eda8f4ae5aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 substitutions for 'beef':\n",
            "granulated_sugar: 0.6888\n",
            "maple_extract: 0.6510\n",
            "sugar: 0.6449\n",
            "almond_extract: 0.6346\n",
            "sucanat: 0.6220\n",
            "white_sugar: 0.6121\n",
            "vanilla: 0.6094\n",
            "brown_sugar: 0.6062\n",
            "maple_flavoring: 0.6015\n",
            "maple_sugar: 0.5999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare validation data\n",
        "val_data = []\n",
        "val_labels = []\n",
        "\n",
        "for _, row in substitution_pairs_df.iterrows():\n",
        "    ing1 = row['ingredient1']\n",
        "    combined_embedding = get_combined_embedding(ing1, model.wv, graph_embeddings)\n",
        "\n",
        "    val_data.append(combined_embedding)\n",
        "    val_labels.append(row['ingredient2'])\n",
        "\n",
        "val_data = np.array(val_data)\n",
        "val_data = torch.tensor(val_data, dtype=torch.float32)\n",
        "val_predictions = nn_model(val_data).detach().numpy()\n"
      ],
      "metadata": {
        "id": "QXKDQ1wIShsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to find the top N most similar ingredients based on cosine similarity\n",
        "def find_top_similar_ingredients(predicted_embedding, combined_embeddings, top_n=10):\n",
        "    similarities = {}\n",
        "    for ingredient, embedding in combined_embeddings.items():\n",
        "        similarity = cosine_similarity(predicted_embedding.reshape(1, -1), embedding.reshape(1, -1))[0][0]\n",
        "        similarities[ingredient] = similarity\n",
        "    sorted_ingredients = sorted(similarities.items(), key=lambda item: item[1], reverse=True)\n",
        "    return [ingredient for ingredient, similarity in sorted_ingredients[:top_n]]\n",
        "\n",
        "# Function to calculate metrics\n",
        "def calculate_metrics(predictions, ground_truths, combined_embeddings, top_n=10, threshold=0.8):\n",
        "    mrr, hit_1, hit_3, hit_10 = 0.0, 0.0, 0.0, 0.0\n",
        "    total = len(ground_truths)\n",
        "\n",
        "    for pred, gt in zip(predictions, ground_truths):\n",
        "        top_similar = find_top_similar_ingredients(pred, combined_embeddings, top_n=top_n)\n",
        "        if gt in top_similar:\n",
        "            rank = top_similar.index(gt) + 1\n",
        "            mrr += 1.0 / rank\n",
        "            if rank == 1:\n",
        "                hit_1 += 1.0\n",
        "            if rank <= 3:\n",
        "                hit_3 += 1.0\n",
        "            if rank <= 10:\n",
        "                hit_10 += 1.0\n",
        "\n",
        "    mrr /= total\n",
        "    hit_1 /= total\n",
        "    hit_3 /= total\n",
        "    hit_10 /= total\n",
        "    return mrr, hit_1, hit_3, hit_10\n",
        "\n",
        "# Calculate metrics for the validation set\n",
        "val_labels_str = val_labels  # Assuming labels are ingredient names\n",
        "combined_embeddings = {ingredient: get_combined_embedding(ingredient, model.wv, graph_embeddings) for ingredient in model.wv.index_to_key}\n",
        "mrr, hit_1, hit_3, hit_10 = calculate_metrics(val_predictions, val_labels_str, combined_embeddings)\n",
        "\n",
        "print(f\"MRR: {mrr:.4f}, Hit@1: {hit_1:.4f}, Hit@3: {hit_3:.4f}, Hit@10: {hit_10:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "43JDrVnKSso6",
        "outputId": "bc55812b-6eed-4630-91cb-c15c53009c73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-c5bb5f4aaea3>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mval_labels_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_labels\u001b[0m  \u001b[0;31m# Assuming labels are ingredient names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mcombined_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mingredient\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_combined_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mingredient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_embeddings\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mingredient\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_to_key\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mmrr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhit_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhit_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhit_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"MRR: {mrr:.4f}, Hit@1: {hit_1:.4f}, Hit@3: {hit_3:.4f}, Hit@10: {hit_10:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-c5bb5f4aaea3>\u001b[0m in \u001b[0;36mcalculate_metrics\u001b[0;34m(predictions, ground_truths, combined_embeddings, top_n, threshold)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mtop_similar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_top_similar_ingredients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombined_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtop_similar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_similar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-c5bb5f4aaea3>\u001b[0m in \u001b[0;36mfind_top_similar_ingredients\u001b[0;34m(predicted_embedding, combined_embeddings, top_n)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msimilarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mingredient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombined_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0msimilarities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mingredient\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msorted_ingredients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                     )\n\u001b[1;32m    213\u001b[0m                 ):\n\u001b[0;32m--> 214\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1582\u001b[0m         \u001b[0mY_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_normalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1584\u001b[0;31m         \u001b[0mY_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1586\u001b[0m     \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_normalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_normalized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdense_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mglobal_skip_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skip_parameter_validation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mfunc_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[1;32m   1873\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"max\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1874\u001b[0m             \u001b[0mnorms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1875\u001b[0;31m         \u001b[0mnorms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_handle_zeros_in_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1876\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnorms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m_handle_zeros_in_scale\u001b[0;34m(scale, copy, constant_mask)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mconstant_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0;31m# New array to avoid side-effects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate metrics with Jaro-Winkler similarity threshold\n",
        "def calculate_metrics(predictions, ground_truths, combined_embeddings, top_n=10, threshold=0.8):\n",
        "    mrr, hit_1, hit_3, hit_10 = 0.0, 0.0, 0.0, 0.0\n",
        "    total = len(ground_truths)\n",
        "\n",
        "    for pred, gt in zip(predictions, ground_truths):\n",
        "        top_similar = find_top_similar_ingredients(pred, combined_embeddings, top_n=top_n)\n",
        "        for rank, candidate in enumerate(top_similar, start=1):\n",
        "            sim = jellyfish.jaro_winkler_similarity(gt, candidate)\n",
        "            if sim >= threshold:\n",
        "                mrr += 1.0 / rank\n",
        "                if rank == 1:\n",
        "                    hit_1 += 1.0\n",
        "                if rank <= 3:\n",
        "                    hit_3 += 1.0\n",
        "                if rank <= 10:\n",
        "                    hit_10 += 1.0\n",
        "                break\n",
        "\n",
        "    mrr /= total\n",
        "    hit_1 /= total\n",
        "    hit_3 /= total\n",
        "    hit_10 /= total\n",
        "    return mrr, hit_1, hit_3, hit_10\n",
        "\n",
        "# Calculate metrics for the validation set\n",
        "val_labels_str = val_labels  # Assuming labels are ingredient names\n",
        "combined_embeddings = {ingredient: get_combined_embedding(ingredient, model.wv, graph_embeddings) for ingredient in model.wv.index_to_key}\n",
        "mrr, hit_1, hit_3, hit_10 = calculate_metrics(val_predictions, val_labels_str, combined_embeddings)\n",
        "\n",
        "print(f\"MRR: {mrr:.4f}, Hit@1: {hit_1:.4f}, Hit@3: {hit_3:.4f}, Hit@10: {hit_10:.4f}\")"
      ],
      "metadata": {
        "id": "hJfi4FzeTNrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "OHeMjgnyNZWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import jellyfish\n",
        "\n",
        "# Prepare validation data for the first 500 entries\n",
        "val_data = []\n",
        "val_labels = []\n",
        "\n",
        "for _, row in substitution_pairs_df.iterrows():\n",
        "    if len(val_data) >= 500:\n",
        "        break\n",
        "    ing1 = row['ingredient1']\n",
        "    combined_embedding = get_combined_embedding(ing1, model.wv, graph_embeddings)\n",
        "\n",
        "    val_data.append(combined_embedding)\n",
        "    val_labels.append(row['ingredient2'])\n",
        "\n",
        "val_data = np.array(val_data)\n",
        "val_data = torch.tensor(val_data, dtype=torch.float32)\n",
        "val_predictions = nn_model(val_data).detach().numpy()\n",
        "\n",
        "# Function to find the top N most similar ingredients based on cosine similarity\n",
        "def find_top_similar_ingredients(predicted_embedding, combined_embeddings, top_n=10):\n",
        "    similarities = {}\n",
        "    for ingredient, embedding in combined_embeddings.items():\n",
        "        similarity = cosine_similarity(predicted_embedding.reshape(1, -1), embedding.reshape(1, -1))[0][0]\n",
        "        similarities[ingredient] = similarity\n",
        "    sorted_ingredients = sorted(similarities.items(), key=lambda item: item[1], reverse=True)\n",
        "    return [ingredient for ingredient, similarity in sorted_ingredients[:top_n]]\n",
        "\n",
        "# Function to calculate metrics with Jaro-Winkler similarity threshold\n",
        "def calculate_metrics(predictions, ground_truths, combined_embeddings, top_n=10, threshold=0.8):\n",
        "    mrr, hit_1, hit_3, hit_10 = 0.0, 0.0, 0.0, 0.0\n",
        "    total = len(ground_truths)\n",
        "\n",
        "    for pred, gt in zip(predictions, ground_truths):\n",
        "        top_similar = find_top_similar_ingredients(pred, combined_embeddings, top_n=top_n)\n",
        "        for rank, candidate in enumerate(top_similar, start=1):\n",
        "            sim = jellyfish.jaro_winkler_similarity(gt, candidate)\n",
        "            if sim >= threshold:\n",
        "                mrr += 1.0 / rank\n",
        "                if rank == 1:\n",
        "                    hit_1 += 1.0\n",
        "                if rank <= 3:\n",
        "                    hit_3 += 1.0\n",
        "                if rank <= 10:\n",
        "                    hit_10 += 1.0\n",
        "                break\n",
        "\n",
        "    mrr /= total\n",
        "    hit_1 /= total\n",
        "    hit_3 /= total\n",
        "    hit_10 /= total\n",
        "    return mrr, hit_1, hit_3, hit_10\n",
        "\n",
        "# Calculate metrics for the first 500 entries of the validation set\n",
        "val_labels_str = val_labels  # Assuming labels are ingredient names\n",
        "combined_embeddings = {ingredient: get_combined_embedding(ingredient, model.wv, graph_embeddings) for ingredient in model.wv.index_to_key}\n",
        "mrr, hit_1, hit_3, hit_10 = calculate_metrics(val_predictions, val_labels_str, combined_embeddings)\n",
        "\n",
        "print(f\"MRR: {mrr:.4f}, Hit@1: {hit_1:.4f}, Hit@3: {hit_3:.4f}, Hit@10: {hit_10:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8jxqShnTeL6",
        "outputId": "a119e0f5-2f56-4a74-9678-f1958b606236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MRR: 0.1257, Hit@1: 0.0780, Hit@3: 0.1420, Hit@10: 0.2680\n"
          ]
        }
      ]
    }
  ]
}