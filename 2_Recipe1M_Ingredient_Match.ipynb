{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "kl05kBuFlicc"
      ],
      "authorship_tag": "ABX9TyNzGU20FJ2+CQ0I4aXL/EM6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JITHIN-ANTONY-JOSEPH/ERP_11358080/blob/main/2_Recipe1M_Ingredient_Match.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mounting and loading the files"
      ],
      "metadata": {
        "id": "kl05kBuFlicc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXp96j7GN3w7",
        "outputId": "49077837-dfd5-4b29-aeb3-de83d5b279bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing required libraries and both the datasets"
      ],
      "metadata": {
        "id": "j0qvbUZulo3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "from concurrent.futures import ProcessPoolExecutor"
      ],
      "metadata": {
        "id": "V3HhHmWnOkT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flavorgraph_df = pd.read_csv('/content/drive/My Drive/ERP/Dataset/nodes_191120.csv')  # Adjust the path as needed , this is the path to my personal Google Drive\n",
        "# Load the Recipe1m dataset from the JSON file\n",
        "with open('/content/drive/My Drive/ERP/Processed_Layer1.json', 'r') as file:  # Adjust the path as needed , this is the path to my personal Google Drive\n",
        "    recipe1m_data = [json.loads(line) for line in file]"
      ],
      "metadata": {
        "id": "higzMY2jRPep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logic sequence to match ingredient names between FlavorGraph and Recipe1M and update/save the Recipe1M"
      ],
      "metadata": {
        "id": "rNr3IZprlu4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract unique ingredients where node_type is \"ingredient\"\n",
        "flavorgraph_ingredients = flavorgraph_df[flavorgraph_df['node_type'] == 'ingredient']['name'].dropna().unique()\n",
        "\n",
        "# Create a mapping from space-separated to underscore-separated ingredients\n",
        "ingredient_mapping = {ingredient.replace('_', ' '): ingredient for ingredient in flavorgraph_ingredients if isinstance(ingredient, str)}\n",
        "\n",
        "# Function to replace space-separated ingredients with underscore-separated ones\n",
        "def replace_ingredients(text, mapping):\n",
        "    # Sort keys by length in descending order to handle multi-word ingredients first\n",
        "    keys_sorted_by_length = sorted(mapping.keys(), key=len, reverse=True)\n",
        "    for key in keys_sorted_by_length:\n",
        "        if key in text:\n",
        "            text = text.replace(key, mapping[key])\n",
        "    return text\n",
        "\n",
        "# Function to process the instructions and ingredients list for each recipe\n",
        "def process_list(item_list, mapping):\n",
        "    return [replace_ingredients(item, mapping) for item in item_list]\n",
        "\n",
        "def process_row(row, mapping):\n",
        "    if isinstance(row['processed_instructions'], list):\n",
        "        row['processed_instructions'] = process_list(row['processed_instructions'], mapping)\n",
        "    if isinstance(row['processed_ingredients'], list):\n",
        "        row['processed_ingredients'] = process_list(row['processed_ingredients'], mapping)\n",
        "    return row\n",
        "\n",
        "# Convert to DataFrame for easier manipulation\n",
        "recipe1m_df = pd.DataFrame(recipe1m_data)\n",
        "\n",
        "# Convert DataFrame to a list of dictionaries for parallel processing\n",
        "recipe1m_records = recipe1m_df.to_dict(orient='records')\n",
        "\n",
        "# Process the DataFrame using parallel processing\n",
        "def parallel_process(records, mapping):\n",
        "    with ProcessPoolExecutor() as executor:\n",
        "        results = list(executor.map(process_row, records, [mapping]*len(records)))\n",
        "    return results\n",
        "\n",
        "processed_records = parallel_process(recipe1m_records, ingredient_mapping)\n",
        "\n",
        "# Convert back to DataFrame\n",
        "recipe1m_df_processed = pd.DataFrame(processed_records)\n",
        "\n",
        "# Convert back to JSON format\n",
        "recipe1m_data_modified = recipe1m_df_processed.to_dict(orient='records')\n",
        "\n",
        "# Save the modified dataset to JSON\n",
        "with open('/content/drive/My Drive/ERP/modified_Processed_Layer1.json', 'w') as file:\n",
        "    for record in recipe1m_data_modified:\n",
        "        file.write(json.dumps(record) + '\\n')\n"
      ],
      "metadata": {
        "id": "sVGHnzY9Xf6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross-Checking expected counts"
      ],
      "metadata": {
        "id": "-DwLoUwXmIvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to DataFrame for easier manipulation\n",
        "recipe1m_df = pd.DataFrame(recipe1m_data)"
      ],
      "metadata": {
        "id": "WDDoQ2cwblFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "partition_counts = recipe1m_df['partition'].value_counts()"
      ],
      "metadata": {
        "id": "yzgwX8oAXdyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "partition_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPTsZYxbbOn6",
        "outputId": "8a355dc0-a493-4a0e-cf7f-f97cb18c520e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "partition\n",
              "train    720639\n",
              "val      155036\n",
              "test     154045\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming recipe1m_df is already loaded and contains the columns 'partition' and 'processed_instructions'\n",
        "keywords = [\"instead\", \"substitute\", \"in place of\", \"replace\"]\n",
        "\n",
        "# Define a function to find the matching keyword\n",
        "def find_keywords(text, keywords):\n",
        "    for keyword in keywords:\n",
        "        if keyword in text:\n",
        "            return keyword\n",
        "    return None\n",
        "\n",
        "# Filter the DataFrame and find the keywords\n",
        "recipe1m_df['keyword'] = recipe1m_df['processed_instructions'].apply(\n",
        "    lambda x: find_keywords(' '.join(x) if isinstance(x, list) else x, keywords))\n",
        "\n",
        "# Filter out rows where no keyword was found\n",
        "filtered_df = recipe1m_df[recipe1m_df['keyword'].notna()]\n",
        "\n",
        "# Group by partition and keyword, then get the counts\n",
        "partition_keyword_counts = filtered_df.groupby(['partition', 'keyword']).size().reset_index(name='counts')\n",
        "\n",
        "# Display the counts\n",
        "print(partition_keyword_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEEh_tzjb5uj",
        "outputId": "0ea4e422-68a4-478d-b893-879ecdb366bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   partition      keyword  counts\n",
            "0       test  in place of     230\n",
            "1       test      instead    1320\n",
            "2       test      replace     739\n",
            "3       test   substitute    1691\n",
            "4      train  in place of    1098\n",
            "5      train      instead    6522\n",
            "6      train      replace    3656\n",
            "7      train   substitute    7704\n",
            "8        val  in place of     255\n",
            "9        val      instead    1446\n",
            "10       val      replace     776\n",
            "11       val   substitute    1636\n"
          ]
        }
      ]
    }
  ]
}